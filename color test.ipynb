{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgnarag/painting_restoration/blob/main/color%20test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gXM5CNP5BaYU",
        "outputId": "edea44b3-8f58-4f93-ad02-642dea4ad907",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/My\\ Drive\n",
        "file_path = \"/content/drive/MyDrive/Baumgartner screenshots/\""
      ],
      "metadata": {
        "id": "xiAgOwvmBcjr",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9754f5a6-d510-4893-f69a-8fe6a6d44e5a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'107.1 syllabus 1SAY1920 FINAL.gdoc'\n",
            " 11_input_flipped_horizontal.png\n",
            " 11_input_flipped_vertical.jpg\n",
            " 11_input.png\n",
            " 11_input_rotated_180_flipped_horizontal.png\n",
            " 11_input_rotated_180_flipped_vertical.jpg\n",
            " 11_input_rotated_180.png\n",
            " 11_input_rotated_270_flipped_horizontal.png\n",
            " 11_input_rotated_270_flipped_vertical.jpg\n",
            " 11_input_rotated_270.png\n",
            " 11_input_rotated_90_flipped_horizontal.png\n",
            " 11_input_rotated_90_flipped_vertical.jpg\n",
            " 11_input_rotated_90.png\n",
            " 11_output_flipped_horizontal.png\n",
            " 11_output_flipped_vertical.jpg\n",
            " 11_output.png\n",
            " 11_output_rotated_180_flipped_horizontal.png\n",
            " 11_output_rotated_180_flipped_vertical.jpg\n",
            " 11_output_rotated_180.png\n",
            " 11_output_rotated_270_flipped_horizontal.png\n",
            " 11_output_rotated_270_flipped_vertical.jpg\n",
            " 11_output_rotated_270.png\n",
            " 11_output_rotated_90_flipped_horizontal.png\n",
            " 11_output_rotated_90_flipped_vertical.jpg\n",
            " 11_output_rotated_90.png\n",
            "'1C-01 Narag et al (1).pdf'\n",
            "'1C-01 Narag et al.pdf'\n",
            "'1FA971504AC646559D05A8ED6341AFB3[1025340].png'\n",
            "'1H-04 Narag et al.pdf'\n",
            " 20220802_182749.heic\n",
            " 20220802_182831.heic\n",
            " 20220802_183259.heic\n",
            " 20220803_125819.heic\n",
            " 20220803_125842.heic\n",
            " 20220803_144229.heic\n",
            " 20220803_144422.heic\n",
            " 20220803_160724.heic\n",
            " 20220803_160751.heic\n",
            " 20220803_165240.heic\n",
            " 20220803_165318.heic\n",
            " 20220803_174701.heic\n",
            " 20220803_174706.heic\n",
            " 20220804_175217.heic\n",
            " 20220804_175443.heic\n",
            " 20220804_175616.heic\n",
            " 20220804_181917.heic\n",
            " 20220804_182007.heic\n",
            " 20220804_182117.heic\n",
            " 2S22-23_LE3-Regular-Set-A-FINAL-KEY.pdf\n",
            "'3 classes (polarized)CM_alexnet.png'\n",
            "'3 classes (polarized)CM_vgg.png'\n",
            "'A4_Physics 71 TWHFU-3_gradesheet (1).pdf'\n",
            "'A4_Physics 71 TWHFU-3_officialgrades (1).pdf'\n",
            "'A4_Physics 71 TWHFU-3_officialgrades.gdoc'\n",
            "'Abstract - NARAG, Mark Jeremy.pdf'\n",
            "'Annex 1 (copy of Journal).pdf'\n",
            "'Annex 2 (Proof of employments).pdf'\n",
            "'App Physics 181 THY-FX-2_studentcontactlist.xlsx'\n",
            " Architectural_designs\n",
            "'Arki abstract.pdf'\n",
            "'Arki full paper.pdf'\n",
            "'[ART] Example of Objectives - Activities - Exp Output OPTIKAL WBS version 2.gsheet'\n",
            " autoencoder_fine_tuned_6\n",
            "'autoencoder_fine_tuned_6 (1)'\n",
            " autoencoder_fine_tuned_6_b\n",
            "'Baumgartner screenshots'\n",
            "'Binarizing architectural drawings'\n",
            " classification_report_nonTL.xlsx\n",
            " classification_report.xlsx\n",
            " Classroom\n",
            "'CLEAN32_AB_INPUT_[09] Preserve and Protect.png'\n",
            "'CLEAN32_AB_TEST_INPUT_[04] Coming into Bloom_V1.png'\n",
            "'CLEAN32LAB_Copy of [05] Comprimise-d - Before.png'\n",
            "'CLEAN_TEST_INPUT_[04] Coming into Bloom.png'\n",
            "'Colab Notebooks'\n",
            "'Color Difference Specification 2016.pptx'\n",
            " confusion_matrix_nonTL.png\n",
            " confusion_matrix_nonTL.xlsx\n",
            " CS284\n",
            " CS_NIP_201819_S2_BS_AppliedPhysics_Narag_Mark_Jeremy.pdf\n",
            " D54dUVpU8AIZzoD.jpeg\n",
            " Data.tex\n",
            "'Dormitory Stay Request MNarag.docx.pdf'\n",
            "'[DRAFT-ART] UP Intelligent Systems Center Research Grant Application - Preview.docx'\n",
            " DrzPc0sUwAAyQHi.jpeg\n",
            " DvO96koV4AAD6PP.jpeg\n",
            "'DvO976tVAAEQ9ym (1).jpeg'\n",
            " DvO976tVAAEQ9ym.jpeg\n",
            "'Employment Survey.gdoc'\n",
            " Fast-Dreambooth\n",
            "'FBC-2_Banez (1).pdf'\n",
            " FBC-2_Banez.pdf\n",
            " FdUaD2nUcAAki1b.jpeg\n",
            "'Figure 1.png'\n",
            "'Figure 2.png'\n",
            "'fingerprint (10).pb'\n",
            "'fingerprint (11).pb'\n",
            "'fingerprint (12).pb'\n",
            "'fingerprint (13).pb'\n",
            "'fingerprint (1).pb'\n",
            "'fingerprint (2).pb'\n",
            "'fingerprint (3).pb'\n",
            "'fingerprint (4).pb'\n",
            "'fingerprint (5).pb'\n",
            "'fingerprint (6).pb'\n",
            "'fingerprint (7).pb'\n",
            "'fingerprint (8).pb'\n",
            "'fingerprint (9).pb'\n",
            " fingerprint.pb\n",
            "'Form5a and Grades.zip'\n",
            " Fringes.zip\n",
            " FSR_120201_NARAG_MARK_JEREMY_GACIAS_NIP.pdf\n",
            " FSR_120202_NARAG_MARK_JEREMY_GACIAS_NIP.pdf\n",
            " FSR_120212_NARAG_MARK_JEREMY_GACIAS_NIP.pdf\n",
            " FSR_120221_NARAG_MARK_JEREMY_GACIAS_NIP.pdf\n",
            "'Geology (Ate Grass)'\n",
            "'Geology (Ate Grass) (1)'\n",
            "'Getting started.pdf'\n",
            " IMG_4258.HEIC\n",
            " IMG_4259.HEIC\n",
            " IMG_4260.HEIC\n",
            " IMG_4261.HEIC\n",
            " IMG_4262.HEIC\n",
            " IMG_4263.HEIC\n",
            " IMG_4288.HEIC\n",
            " IMG_5634.JPG\n",
            " IMG_6572.jpeg\n",
            " IMG_6578.jpeg\n",
            "'IMG_6587 (1).jpeg'\n",
            " IMG_6587.jpeg\n",
            " IPA-Form4.1-2021Rev072021-1.pdf\n",
            " IPA-Form4.2-2021Rev072021.docx\n",
            " IPA-Form4.3-2021Rev072021.pdf\n",
            "'item sample.tex'\n",
            "'item template.tex'\n",
            "'Jas Jem utang.gsheet'\n",
            " Jem_face\n",
            "'JFR Reduced Fees for 1st Sem AY 20-21.zip'\n",
            "'Lecture 22 - Torque.pptx'\n",
            "'Lecture 23 - Dynamics of Rotation.pptx'\n",
            "'Lecture 24 - Angular Momentum.pptx'\n",
            "'Lecture 25 - Equilibrium and Center of Gravity.pptx'\n",
            "'Lecture 26 - Density and Pressure in a Fluid.pptx'\n",
            "'Lecture 27 - Buoyancy.pptx'\n",
            "'LRM_20220804_195432 (1).dng'\n",
            " LRM_20220804_195432.dng\n",
            " LRM_20220804_195500.dng\n",
            " LRM_20220804_195546.dng\n",
            " LRM_20220805_113837.dng\n",
            " LRM_20220805_142837.dng\n",
            " LRM_20220805_143054.dng\n",
            " LRM_20220805_143817.dng\n",
            "'MALIPOL_CHAE ANN.pdf'\n",
            "'Method_6_8_L_AB_[08] Conserving a Moroccan Portrait - Before.png'\n",
            " Metric_100dpi.csv\n",
            " Metric_500.csv\n",
            "'NARAG_MARKJEREMY (1).BC.pdf'\n",
            " NARAG_MARKJEREMY.BC.pdf\n",
            " NARAG_MARKJEREMY.CC.png\n",
            " NARAG_MARKJEREMY.dcog.pdf\n",
            " NARAG_MARKJEREMY.DC.pdf\n",
            " NARAG_MARKJEREMY.FL.pdf\n",
            " NARAG_MARKJEREMY.Form1.1.pdf\n",
            " NARAG_MARKJEREMY.POS.pdf\n",
            " NARAG_MARKJEREMY.SD.pdf\n",
            " NARAG_MARKJEREMY.TCGTOR.pdf\n",
            "'[NARAG] Physics 242 Final Report.pdf'\n",
            "'[NARAG] Physics 242 PS 1.pdf'\n",
            "'[NARAG] Physics 242 PS 2.pdf'\n",
            "'Narag SPP Cert.pdf'\n",
            " NARAG_Travel-Report-Form-2019.pdf\n",
            "'NIP COVID-19 Case Report Form.gform'\n",
            "'NIP COVID-19 Case Report Form (Responses).gsheet'\n",
            "'NIP COVID19 Report.gsheet'\n",
            "'NIP Year End Party 2022'\n",
            " NRAG_MARKJEREMY.OTRTCG.pdf\n",
            "'Optics in Art and Art Analysis (1).pptx'\n",
            "'Optics in Art and Art Analysis.pptx'\n",
            "'OUR CErtificate.gdoc'\n",
            "'OUR CErtificate.pdf'\n",
            "'output v1_100dpi.png'\n",
            "'output v2_100dpi.png'\n",
            "'output v3_100dpi.png'\n",
            "'output v3_500.png'\n",
            "'output v4_100dpi.png'\n",
            "'output v5_100dpi.png'\n",
            "'output v6_100dpi.png'\n",
            "'OVCRD IPA Reference Slip (2021-0929-1691-5873).pdf'\n",
            "'PA-08 Narag et al.pdf'\n",
            " PA-08.pdf\n",
            "'Parallel Presentation.gslides'\n",
            "'PEER EVALUTION - Physics 72.1 HBC-1 .gform'\n",
            "'PEER EVALUTION - Physics 72.1 TDE-1 .gform'\n",
            "'PEER EVALUTION - Physics 72.1 WDE-1 .gform'\n",
            "'PhD Candidacy Slides.pdf'\n",
            "'PhD Candidacy Slides.pptx'\n",
            "'Physics 107.1 Drive'\n",
            "'Physics 107.1 MBCD-2_studentcontactlist.xlsx'\n",
            " Physics305_plasma\n",
            "'Physics 71.1 WIJ FIJ and 72.1 TBC.gsheet'\n",
            " Physics_71_Syllabus.zip\n",
            "'Physics_71_Syllabus.zip (Unzipped Files)'\n",
            "'[Physics 71 V-2] Attendance.gsheet'\n",
            "'Physics 72.1 2nd Sem AY 2019-2020.gsheet'\n",
            "'_quadrant1_[08] Conserving a Moroccan Portrait.png'\n",
            "'quadrant1_[08] Conserving a Moroccan Portrait.png'\n",
            "'_quadrant2_[08] Conserving a Moroccan Portrait.png'\n",
            "'quadrant2_[08] Conserving a Moroccan Portrait.png'\n",
            "'_quadrant4_[08] Conserving a Moroccan Portrait.png'\n",
            "'quadrant4_[08] Conserving a Moroccan Portrait.png'\n",
            "'Rene Jem utang.gsheet'\n",
            "'Research files'\n",
            "'Sablay picture.jpeg'\n",
            "'saved_model (10).pb'\n",
            "'saved_model (11).pb'\n",
            "'saved_model (12).pb'\n",
            "'saved_model (13).pb'\n",
            "'saved_model (1).pb'\n",
            "'saved_model (2).pb'\n",
            "'saved_model (3).pb'\n",
            "'saved_model (4).pb'\n",
            "'saved_model (5).pb'\n",
            "'saved_model (6).pb'\n",
            "'saved_model (7).pb'\n",
            "'saved_model (8).pb'\n",
            "'saved_model (9).pb'\n",
            " saved_model.pb\n",
            "'Screenshot 2023-02-12 at 12.13.51 (1).png'\n",
            "'Screenshot 2023-02-12 at 12.13.51.png'\n",
            "'Screenshot 2023-06-29 at 19.20.04.png'\n",
            "'Screenshot 2023-06-29 at 19.26.09.png'\n",
            " sd\n",
            " Smokers.mp4\n",
            "'SORRY SIR HUHU.gdoc'\n",
            "'SORRY SIR HUHU.pdf'\n",
            "'SPP-2023-1H-04 (1).pptx'\n",
            " SPP-2023-1H-04.pptx\n",
            " SPP_2023-Contributed-26.pdf\n",
            "'SPP-2023-PB-05  .pdf'\n",
            " SPP_Appearance-45.pdf\n",
            "'SPP Cert of Appearance NARAG (1).pdf'\n",
            "'SPP Cert of Appearance NARAG (2).pdf'\n",
            "'SPP Cert of Appearance NARAG.pdf'\n",
            "'Testing on DIV2K dataset.pdf'\n",
            "'[THY-FX] Physics 181 LE1 Submissions 2nd Sem AY 2020-21'\n",
            " Travel-Report-Form-2019.pdf\n",
            "'Undergraduate Research'\n",
            "'Untitled spreadsheet (1).gsheet'\n",
            "'Untitled spreadsheet.gsheet'\n",
            "'[Updated] Physics 71 THQ-FQ-1_studentcontactlist (1).xlsx'\n",
            "'[Updated] Physics 71 THQ-FQ-1_studentcontactlist.xlsx'\n",
            "'variables (10).data-00000-of-00001'\n",
            "'variables (11).data-00000-of-00001'\n",
            "'variables (12).data-00000-of-00001'\n",
            "'variables (13).data-00000-of-00001'\n",
            "'variables (1).data-00000-of-00001'\n",
            "'variables (2).data-00000-of-00001'\n",
            "'variables (3).data-00000-of-00001'\n",
            "'variables (4).data-00000-of-00001'\n",
            "'variables (5).data-00000-of-00001'\n",
            "'variables (6).data-00000-of-00001'\n",
            "'variables (7).data-00000-of-00001'\n",
            "'variables (8).data-00000-of-00001'\n",
            "'variables (9).data-00000-of-00001'\n",
            " variables.data-00000-of-00001\n",
            "'Waiver for more than 18 units [2nd sem AY 20-21].gdoc'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing packages"
      ],
      "metadata": {
        "id": "zEoJQzJ5bM8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image, ImageOps\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import zoom\n",
        "\n",
        "import cv2\n",
        "from skimage import color\n",
        "\n",
        "from tensorflow import keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import PIL\n",
        "PIL.Image.MAX_IMAGE_PIXELS = 236958876\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "FgE9bH4-MFlB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining functions"
      ],
      "metadata": {
        "id": "ihq928NMbTBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rgb_lab_normalized(im):\n",
        "    rgb_array = np.array(im) # Convert to numpy array\n",
        "    rgb_array_normalized = rgb_array / 255.0 # Normalize RGB values from 0 to 1\n",
        "    lab_array_normalized = color.rgb2lab(rgb_array_normalized) # Convert RGB to LAB colorspace\n",
        "    lab_array_normalized[..., 0] = (lab_array_normalized[..., 0]) / 100.0 # Scale LAB values to range [0, 1]\n",
        "    lab_array_normalized[..., 1] = (lab_array_normalized[..., 1] + 128) / 255.0\n",
        "    lab_array_normalized[..., 2] = (lab_array_normalized[..., 2] + 128) / 255.0\n",
        "    lab_image_normalized = Image.fromarray((lab_array_normalized * 255).astype(np.uint8), mode='LAB')# Convert LAB array back to image\n",
        "    return lab_image_normalized"
      ],
      "metadata": {
        "id": "GRBwljTxNi-i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model"
      ],
      "metadata": {
        "id": "3lnB29-_cVp-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model RGB:**"
      ],
      "metadata": {
        "id": "EWPFTVoVxePF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_size = 8\n",
        "size = 8\n",
        "\n",
        "def rgb_L_ab(rgb_image, test_L):\n",
        "    lab_array = color.rgb2lab(np.array(rgb_image))# Convert RGB to LAB colorspace\n",
        "    lab_array[..., 0] = test_L #Change L channel to input\n",
        "    rgb_array = color.lab2rgb(lab_array)# Convert back LAB to RGB colorspace\n",
        "    rgb_array = (rgb_array*255).astype(np.uint8)# Scale RGB values back to the range [0, 255]\n",
        "    rgb_array = Image.fromarray(rgb_array, mode='RGB')# Convert RGB array back to image\n",
        "    return rgb_array\n",
        "\n",
        "autoencoder = keras.models.load_model(file_path + 'Model/portion only/unet_'+str(n_size)+'_rgb')\n",
        "\n",
        "input_folder_path = file_path+ \"Testing/portion only/color test/\"\n",
        "input_files = sorted(os.listdir(input_folder_path))\n",
        "\n",
        "for index, image_file in enumerate(input_files):\n",
        "    image_path = os.path.join(input_folder_path, image_file)\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    test_L = color.rgb2lab(np.array(image))\n",
        "    test_L = test_L[..., 0]\n",
        "    image = np.array(image).astype(np.float32) / 255.0# Convert image to numpy array and scale pixel values to [0, 1]\n",
        "    image = np.expand_dims(image, axis=0)# Expand dimensions to match the expected input shape (1, 8, 8, 3)\n",
        "\n",
        "    decoded_imgs = autoencoder.predict(image)\n",
        "    final = (decoded_imgs*255).astype('uint8')\n",
        "\n",
        "    #----------------TEST ON FULL RGB--------------------#\n",
        "    final_rgb = final\n",
        "    final_rgb = np.squeeze(final_rgb)\n",
        "    reconstructed_rgb = Image.fromarray(final_rgb)\n",
        "    reconstructed_rgb.save(file_path + \"Testing/portion only/color test out/\"+\"Method_1_\"+image_file)\n",
        "\n",
        "\n",
        "    #plt.figure(), plt.imshow(reconstructed_rgb)\n",
        "\n",
        "    #----------------TEST ON L from input and AB from convert RGB2LAB of model--------------------#\n",
        "    final_lab = rgb_L_ab(final_rgb, test_L)\n",
        "    final_lab = np.squeeze(final_lab)\n",
        "    reconstructed_lab = Image.fromarray(final_lab)\n",
        "    reconstructed_lab.save(file_path + \"Testing/portion only/color test out/\"+\"Method_2_\"+image_file)\n",
        "    #plt.figure(), plt.imshow(reconstructed_lab)"
      ],
      "metadata": {
        "id": "y3j1v9uGdbTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19103a1e-3b84-4473-ca68-a5a15b55b8eb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 141ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model LAB:**"
      ],
      "metadata": {
        "id": "kvODWjVrxmRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import PIL\n",
        "PIL.Image.MAX_IMAGE_PIXELS = 236958876\n",
        "\n",
        "n_size = 8\n",
        "size = n_size\n",
        "\n",
        "def lab_rgb_unnormalized(lab_image):\n",
        "    lab_array = np.array(lab_image/255)# Convert LAB image to numpy array\n",
        "    lab_array[..., 0] = lab_array[..., 0] * 100.0# Scale LAB values back to their original ranges\n",
        "    lab_array[..., 1] = (lab_array[..., 1] * 255.0) - 128\n",
        "    lab_array[..., 2] = (lab_array[..., 2] * 255.0) - 128\n",
        "    rgb_array_unnormalized = color.lab2rgb(lab_array)# Convert LAB to RGB colorspace\n",
        "    rgb_array_unnormalized = (rgb_array_unnormalized * 255).astype(np.uint8)# Scale RGB values back to the range [0, 255]\n",
        "    rgb_image_unnormalized = Image.fromarray(rgb_array_unnormalized, mode='RGB')# Convert RGB array back to image\n",
        "    return rgb_image_unnormalized\n",
        "\n",
        "def AB_rgb_unnormalized(lab_image, test_L):\n",
        "    lab_array = np.array(lab_image/255)# Convert LAB image to numpy array\n",
        "    lab_array[..., 0] = test_L #replacing L from the original input\n",
        "    lab_array[..., 1] = (lab_array[..., 1] * 255.0) - 128\n",
        "    lab_array[..., 2] = (lab_array[..., 2] * 255.0) - 128\n",
        "    rgb_array_unnormalized = color.lab2rgb(lab_array)# Convert LAB to RGB colorspace\n",
        "    rgb_array_unnormalized = (rgb_array_unnormalized * 255).astype(np.uint8)# Scale RGB values back to the range [0, 255]\n",
        "    rgb_image_unnormalized = Image.fromarray(rgb_array_unnormalized, mode='RGB')# Convert RGB array back to image\n",
        "    return rgb_image_unnormalized\n",
        "\n",
        "\n",
        "autoencoder = keras.models.load_model(file_path + 'Model/portion only/unet_'+str(n_size)+'_lab')\n",
        "\n",
        "input_folder_path = file_path+ \"Testing/portion only/color test/\"\n",
        "input_files = sorted(os.listdir(input_folder_path))\n",
        "\n",
        "for index, image_file in enumerate(input_files):\n",
        "    image_path = os.path.join(input_folder_path, image_file)\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    test_L = color.rgb2lab(np.array(image))\n",
        "    test_L = test_L[..., 0]\n",
        "    image = rgb_lab_normalized(image)\n",
        "    image = np.array(image).astype(np.float32) / 255.0# Convert image to numpy array and scale pixel values to [0, 1]\n",
        "    image = np.expand_dims(image, axis=0)# Expand dimensions to match the expected input shape (1, 8, 8, 3)\n",
        "\n",
        "    decoded_imgs = autoencoder.predict(image)\n",
        "    final = (decoded_imgs*255).astype('uint8')\n",
        "\n",
        "    #----------------TEST ON FULL LAB--------------------#\n",
        "    final_LAB = lab_rgb_unnormalized(np.squeeze(final))\n",
        "    final_LAB = np.squeeze(final_LAB)\n",
        "    reconstructed_LAB = Image.fromarray(final_LAB)\n",
        "    reconstructed_LAB.save(file_path + \"Testing/portion only/color test out/\"+\"Method_3_\"+image_file)\n",
        "    #plt.figure(), plt.imshow(reconstructed_LAB)\n",
        "\n",
        "    #----------------TEST ON L from input and AB from model--------------------#\n",
        "    final_L_AB = AB_rgb_unnormalized(np.squeeze(final), test_L)\n",
        "    final_L_AB = np.squeeze(final_L_AB)\n",
        "    reconstructed_L_AB = Image.fromarray(final_L_AB)\n",
        "    reconstructed_L_AB.save(file_path + \"Testing/portion only/color test out/\"+\"Method_4_\"+image_file)\n",
        "    #plt.figure(), plt.imshow(reconstructed_L_AB)"
      ],
      "metadata": {
        "id": "l2WOweoWxWeB",
        "outputId": "0f89ce06-41b5-4684-db7b-aa8bc0433644",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model AB**"
      ],
      "metadata": {
        "id": "2ij1l4JRyQ3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import PIL\n",
        "PIL.Image.MAX_IMAGE_PIXELS = 236958876\n",
        "\n",
        "n_size = 8\n",
        "size = n_size\n",
        "\n",
        "def rgb_lab_normalized(im):\n",
        "    rgb_array = np.array(im) # Convert to numpy array\n",
        "    rgb_array_normalized = rgb_array / 255.0 # Normalize RGB values from 0 to 1\n",
        "    lab_array_normalized = color.rgb2lab(rgb_array_normalized) # Convert RGB to LAB colorspace\n",
        "    lab_array_normalized[..., 0] = (lab_array_normalized[..., 0]) / 100.0 # Scale LAB values to range [0, 1]\n",
        "    lab_array_normalized[..., 1] = (lab_array_normalized[..., 1] + 128) / 255.0\n",
        "    lab_array_normalized[..., 2] = (lab_array_normalized[..., 2] + 128) / 255.0\n",
        "    lab_image_normalized = Image.fromarray((lab_array_normalized * 255).astype(np.uint8), mode='LAB')# Convert LAB array back to image\n",
        "    return lab_image_normalized\n",
        "\n",
        "def AB_rgb_unnormalized(ab_image, test_L):\n",
        "    ab_array = np.array(ab_image)/255# Convert LAB image to numpy array\n",
        "    ab_array[..., 0] = (ab_array[..., 0] * 255.0) - 128\n",
        "    ab_array[..., 1] = (ab_array[..., 1] * 255.0) - 128\n",
        "    LAB_array = np.dstack((test_L, ab_array[:,:,0], ab_array[:,:,1]))\n",
        "    rgb_array_unnormalized = color.lab2rgb(LAB_array)# Convert LAB to RGB colorspace\n",
        "    rgb_array_unnormalized = (rgb_array_unnormalized * 255).astype(np.uint8)# Scale RGB values back to the range [0, 255]\n",
        "    rgb_image_unnormalized = Image.fromarray(rgb_array_unnormalized, mode='RGB')# Convert RGB array back to image\n",
        "    return rgb_image_unnormalized\n",
        "\n",
        "autoencoder = keras.models.load_model(file_path + 'Model/portion only/unet_'+str(n_size)+'_ab')\n",
        "\n",
        "input_folder_path = file_path+ \"Testing/portion only/color test/\"\n",
        "input_files = sorted(os.listdir(input_folder_path))\n",
        "\n",
        "for index, image_file in enumerate(input_files):\n",
        "    image_path = os.path.join(input_folder_path, image_file)\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    test_L = color.rgb2lab(np.array(image))\n",
        "    test_L = np.array(test_L[..., 0]).astype('uint8')\n",
        "    image = rgb_lab_normalized(image)\n",
        "    image = np.array(image).astype(np.float32) / 255.0# Convert image to numpy array and scale pixel values to [0, 1]\n",
        "    image = np.expand_dims(image, axis=0)# Expand dimensions to match the expected input shape (1, 8, 8, 3)\n",
        "\n",
        "    decoded_imgs = autoencoder.predict(image[:,:,:,1:3])\n",
        "    final = (decoded_imgs*255).astype('uint8')\n",
        "\n",
        "    #----------------TEST ON L from input and AB from model--------------------#\n",
        "    final_L_AB = AB_rgb_unnormalized(np.squeeze(final), test_L)\n",
        "    final_L_AB = np.squeeze(final_L_AB)\n",
        "    reconstructed_L_AB = Image.fromarray(final_L_AB)\n",
        "    reconstructed_L_AB.save(file_path + \"Testing/portion only/color test out/\"+\"Method_5_\"+image_file)\n",
        "    #plt.figure(), plt.imshow(reconstructed_L_AB)"
      ],
      "metadata": {
        "id": "jrXxXGj5yFs3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed0d733-0f99-4328-cd90-c1dfb77d7758"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model AB plus Model L**"
      ],
      "metadata": {
        "id": "EzOXFu1uyjLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow import keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import PIL\n",
        "PIL.Image.MAX_IMAGE_PIXELS = 236958876\n",
        "\n",
        "n_size = 8\n",
        "size = 8\n",
        "\n",
        "def rgb_lab_normalized(im):\n",
        "    rgb_array = np.array(im) # Convert to numpy array\n",
        "    rgb_array_normalized = rgb_array / 255.0 # Normalize RGB values from 0 to 1\n",
        "    lab_array_normalized = color.rgb2lab(rgb_array_normalized) # Convert RGB to LAB colorspace\n",
        "    lab_array_normalized[..., 0] = (lab_array_normalized[..., 0]) / 100.0 # Scale LAB values to range [0, 1]\n",
        "    lab_array_normalized[..., 1] = (lab_array_normalized[..., 1] + 128) / 255.0\n",
        "    lab_array_normalized[..., 2] = (lab_array_normalized[..., 2] + 128) / 255.0\n",
        "    lab_image_normalized = Image.fromarray((lab_array_normalized * 255).astype(np.uint8), mode='LAB')# Convert LAB array back to image\n",
        "    return lab_image_normalized\n",
        "\n",
        "def L_AB_rgb_unnormalized(ab_image, final_L):\n",
        "    ab_image = ab_image/255.0\n",
        "    final_L = final_L/255.0\n",
        "    final_L[..., 0] = final_L[..., 0]*100.0\n",
        "    ab_image[..., 0] = (ab_image[..., 0] * 255.0) - 128\n",
        "    ab_image[..., 1] = (ab_image[..., 1] * 255.0) - 128\n",
        "    LAB_array = np.dstack((final_L, ab_image[:,:,0], ab_image[:,:,1]))\n",
        "    rgb_array_unnormalized = color.lab2rgb(LAB_array)# Convert LAB to RGB colorspace\n",
        "    rgb_array_unnormalized = (rgb_array_unnormalized * 255).astype(np.uint8)# Scale RGB values back to the range [0, 255]\n",
        "    rgb_image_unnormalized = Image.fromarray(rgb_array_unnormalized, mode='RGB')# Convert RGB array back to image\n",
        "    return rgb_image_unnormalized\n",
        "\n",
        "\n",
        "#----------------GETTING L--------------------#\n",
        "autoencoder_L = keras.models.load_model(file_path + 'Model/portion only/unet_'+str(n_size)+'_L')\n",
        "autoencoder_ab = keras.models.load_model(file_path + 'Model/portion only/unet_'+str(n_size)+'_ab')\n",
        "\n",
        "input_folder_path = file_path+ \"Testing/portion only/color test/\"\n",
        "input_files = sorted(os.listdir(input_folder_path))\n",
        "\n",
        "for index, image_file in enumerate(input_files):\n",
        "    image_path = os.path.join(input_folder_path, image_file)\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = rgb_lab_normalized(image)\n",
        "    image = np.array(image).astype(np.float32) / 255.0# Convert image to numpy array and scale pixel values to [0, 1]\n",
        "    image = np.expand_dims(image, axis=0)# Expand dimensions to match the expected input shape (1, 8, 8, 3)\n",
        "\n",
        "    decoded_imgs = autoencoder_L.predict(image[:,:,:,0:1])\n",
        "    final_L = (decoded_imgs*255).astype('uint8')\n",
        "\n",
        "#----------------GETTING AB--------------------#\n",
        "    image_path = os.path.join(input_folder_path, image_file)\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = rgb_lab_normalized(image)\n",
        "    image = np.array(image).astype(np.float32) / 255.0# Convert image to numpy array and scale pixel values to [0, 1]\n",
        "    image = np.expand_dims(image, axis=0)# Expand dimensions to match the expected input shape (1, 8, 8, 3)\n",
        "\n",
        "    decoded_imgs = autoencoder_ab.predict(image[:,:,:,1:3])\n",
        "    final_ab = (decoded_imgs*255).astype('uint8')\n",
        "\n",
        "\n",
        "    #----------------TEST ON L from model and AB from model--------------------#\n",
        "    final_L_AB = L_AB_rgb_unnormalized(np.squeeze(final_ab), np.squeeze(final_L, axis=0))\n",
        "    final_L_AB = np.squeeze(final_L_AB)\n",
        "    reconstructed_L_AB = Image.fromarray(final_L_AB)\n",
        "    reconstructed_L_AB.save(file_path + \"Testing/portion only/color test out/\"+\"Method_6_\"+image_file)\n",
        "    #plt.figure(), plt.imshow(reconstructed_L_AB)"
      ],
      "metadata": {
        "id": "LTH18YqyypPw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5796de7c-a5a8-4ffe-cf1a-594943f85d88"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute delta E color error tendency"
      ],
      "metadata": {
        "id": "ETEIaIvQcY2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from skimage import io\n",
        "\n",
        "def delta_e_cie2000(lab1, lab2):\n",
        "    # Constants\n",
        "    kL = 1\n",
        "    kC = 1\n",
        "    kH = 1\n",
        "\n",
        "    L1, a1, b1 = lab1\n",
        "    L2, a2, b2 = lab2\n",
        "\n",
        "    # CIE 2000 formula\n",
        "    L_bar_prime = 0.5 * (L1 + L2)\n",
        "    C1 = np.sqrt(a1**2 + b1**2)\n",
        "    C2 = np.sqrt(a2**2 + b2**2)\n",
        "    C_bar = 0.5 * (C1 + C2)\n",
        "    C_bar7 = C_bar**7\n",
        "\n",
        "    G = 0.5 * (1 - np.sqrt(C_bar7 / (C_bar7 + 25**7)))\n",
        "    a1_prime = (1 + G) * a1\n",
        "    a2_prime = (1 + G) * a2\n",
        "\n",
        "    C1_prime = np.sqrt(a1_prime**2 + b1**2)\n",
        "    C2_prime = np.sqrt(a2_prime**2 + b2**2)\n",
        "    C_bar_prime = 0.5 * (C1_prime + C2_prime)\n",
        "\n",
        "    h1_prime = np.degrees(np.arctan2(b1, a1_prime)) % 360\n",
        "    h2_prime = np.degrees(np.arctan2(b2, a2_prime)) % 360\n",
        "\n",
        "    H_bar_prime = h1_prime + h2_prime\n",
        "    if abs(h1_prime - h2_prime) > 180:\n",
        "        H_bar_prime += 360\n",
        "    H_bar_prime *= 0.5\n",
        "\n",
        "    T = 1 - 0.17 * np.cos(np.radians(H_bar_prime - 30)) \\\n",
        "        + 0.24 * np.cos(np.radians(2 * H_bar_prime)) \\\n",
        "        + 0.32 * np.cos(np.radians(3 * H_bar_prime + 6)) \\\n",
        "        - 0.20 * np.cos(np.radians(4 * H_bar_prime - 63))\n",
        "\n",
        "    delta_h_prime = h2_prime - h1_prime\n",
        "    if abs(delta_h_prime) > 180:\n",
        "        if h2_prime <= h1_prime:\n",
        "            delta_h_prime += 360\n",
        "        else:\n",
        "            delta_h_prime -= 360\n",
        "\n",
        "    delta_L_prime = L2 - L1\n",
        "    delta_C_prime = C2_prime - C1_prime\n",
        "    delta_H_prime = 2 * np.sqrt(C1_prime * C2_prime) * np.sin(np.radians(delta_h_prime * 0.5))\n",
        "\n",
        "    S_L = 1 + ((0.015 * (L_bar_prime - 50) ** 2) / np.sqrt(20 + (L_bar_prime - 50) ** 2))\n",
        "    S_C = 1 + 0.045 * C_bar_prime\n",
        "    S_H = 1 + 0.015 * C_bar_prime * T\n",
        "\n",
        "    delta_theta = 30 * np.exp(-(((H_bar_prime - 275) / 25) ** 2))\n",
        "    R_C = 2 * np.sqrt(C_bar7 / (C_bar7 + 25**7))\n",
        "    R_T = -R_C * np.sin(2 * np.radians(delta_theta))\n",
        "\n",
        "    delta_E = np.sqrt(\n",
        "        (delta_L_prime / (kL * S_L)) ** 2 +\n",
        "        (delta_C_prime / (kC * S_C)) ** 2 +\n",
        "        (delta_H_prime / (kH * S_H)) ** 2 +\n",
        "        R_T * (delta_C_prime / (kC * S_C)) * (delta_H_prime / (kH * S_H))\n",
        "    )\n",
        "\n",
        "    return delta_E\n",
        "\n",
        "\n",
        "def color_error(image1_path,image2_path):\n",
        "    image1 = io.imread(image1_path)\n",
        "    image2 = io.imread(image2_path)\n",
        "    # Ensure images are in uint8 format\n",
        "    if image1.dtype != np.uint8:\n",
        "        image1 = (image1 * 255).astype(np.uint8)\n",
        "    if image2.dtype != np.uint8:\n",
        "        image2 = (image2 * 255).astype(np.uint8)\n",
        "    # Remove the alpha channel if it exists\n",
        "    if image1.shape[-1] == 4:\n",
        "        image1 = image1[..., :3]\n",
        "    if image2.shape[-1] == 4:\n",
        "        image2 = image2[..., :3]\n",
        "    # Ensure the images have the same dimensions\n",
        "    if image1.shape != image2.shape:\n",
        "        raise ValueError(\"Images must have the same dimensions\")\n",
        "    # Convert images to LAB color space\n",
        "    image1_lab = cv2.cvtColor(image1, cv2.COLOR_RGB2LAB)\n",
        "    image2_lab = cv2.cvtColor(image2, cv2.COLOR_RGB2LAB)\n",
        "\n",
        "    # Scale LAB values to match theoretical ranges\n",
        "    image1_lab = np.copy(image1_lab).astype(np.float64)\n",
        "    image2_lab = np.copy(image2_lab).astype(np.float64)\n",
        "\n",
        "    image1_lab[:, :, 0] = image1_lab[:, :, 0] * (100 / 255)  # L channel\n",
        "    image1_lab[:, :, 1] = image1_lab[:, :, 1] - 128          # a channel\n",
        "    image1_lab[:, :, 2] = image1_lab[:, :, 2] - 128          # b channel\n",
        "\n",
        "    image2_lab[:, :, 0] = image2_lab[:, :, 0] * (100 / 255)  # L channel\n",
        "    image2_lab[:, :, 1] = image2_lab[:, :, 1] - 128          # a channel\n",
        "    image2_lab[:, :, 2] = image2_lab[:, :, 2] - 128          # b channel\n",
        "\n",
        "    # Flatten the images for easier processing\n",
        "    image1_lab_flat = image1_lab.reshape((-1, 3))\n",
        "    image2_lab_flat = image2_lab.reshape((-1, 3))\n",
        "\n",
        "    # Compute Delta E 2000 for each pair of pixels\n",
        "    delta_e_values = np.array([delta_e_cie2000(lab1, lab2) for lab1, lab2 in zip(image1_lab_flat, image2_lab_flat)])\n",
        "    delta_e_values_mean = np.mean(delta_e_values)\n",
        "    # Reshape the delta_e_values to match the image dimensions, if u wanna plot\n",
        "    #delta_e_image = delta_e_values.reshape(image1_lab.shape[:2])\n",
        "    return delta_e_values_mean"
      ],
      "metadata": {
        "id": "hhH5Kp8uSUOq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groundtruth_folder_path = file_path+ \"Testing/portion only/color test gt/\"\n",
        "gt_files = sorted(os.listdir(groundtruth_folder_path))\n",
        "\n",
        "out_methods_folder_path = file_path+ \"Testing/portion only/color test out/\"\n",
        "out_files = sorted(os.listdir(out_methods_folder_path))\n",
        "\n",
        "method_scores = []\n",
        "for method in range(1,7):\n",
        "  patch_scores = []\n",
        "  for index in range(1,len(gt_files)+1):\n",
        "      gt_path = groundtruth_folder_path + str(index) + '_output.png'\n",
        "      out_path_1 = out_methods_folder_path + 'Method_' + str(method) +'_' + str(index) + '_input.png'\n",
        "      col_er = color_error(gt_path,out_path_1)\n",
        "      patch_scores.append(col_er)\n",
        "  patch_scores.append(np.mean(patch_scores))\n",
        "  method_scores.append(patch_scores)\n",
        "\n",
        "\n",
        "print(np.transpose(method_scores))\n",
        "\n",
        "headers = ['Method 1', 'Method 2', 'Method 3','Method 4', 'Method 5', 'Method 6']\n",
        "row_labels  = ['patch 1', 'patch 2', 'patch 3', 'patch 4', 'patch 5','patch 6', 'patch 7', 'patch 8', 'patch 9', 'patch 10', 'mean']\n",
        "df = pd.DataFrame(np.transpose(method_scores), columns=headers, index=row_labels)\n",
        "df.to_csv(file_path+ \"Testing/portion only/\" + 'delta E scores.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljeKeTdQSg3V",
        "outputId": "15fa7b5a-ca4f-4622-deed-faeed64f4ba5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.33088927  9.22993217  4.19704026  8.87304721  9.0710971   1.74086482]\n",
            " [ 4.16699625  5.84282112  6.25068192  6.36880062  5.93772449  5.60767033]\n",
            " [ 1.72944715 10.24526753  1.91172281 10.28487624 10.68379088  2.70266606]\n",
            " [ 8.1407806  17.10550712  8.15147644 17.0484339  17.50279882  8.79099957]\n",
            " [ 7.52096092 10.46729047  5.62313762  9.56430498 10.61862395  7.07541679]\n",
            " [ 1.61915896 10.03848151  2.3316626  10.19725899 10.5663474   2.26438981]\n",
            " [14.69229855 12.09464031  7.55449134 12.58904664 12.81366893  5.35223015]\n",
            " [ 6.10201367  2.7960763   4.18092255  4.43788259  3.55569328  2.02408401]\n",
            " [ 8.18594282  6.44427579  7.85866606  6.16466015  6.20930828  7.9475751 ]\n",
            " [ 5.35897252  8.11007672  5.15466822  7.94801559  9.85064997  8.17166334]\n",
            " [ 6.08474607  9.2374369   5.32144698  9.34763269  9.68097031  5.167756  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For plotting only:"
      ],
      "metadata": {
        "id": "U1-E7iEbeQ5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "groundtruth_folder_path = file_path+ \"Testing/portion only/color test gt/\"\n",
        "gt_files = sorted(os.listdir(groundtruth_folder_path))\n",
        "\n",
        "out_methods_folder_path = file_path+ \"Testing/portion only/color test out/\"\n",
        "out_files = sorted(os.listdir(out_methods_folder_path))\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=10, figsize=(20, 4))\n",
        "\n",
        "method  = 6\n",
        "\n",
        "for index in range(1,len(gt_files)+1):\n",
        "    gt_path = groundtruth_folder_path + str(index) + '_output.png'\n",
        "    out_path_1 = out_methods_folder_path + 'Method_' + str(method) +'_' + str(index) + '_input.png'\n",
        "\n",
        "    gt_image = Image.open(gt_path)\n",
        "    out_image_1 = Image.open(out_path_1)\n",
        "\n",
        "    # Plot ground truth image\n",
        "    ax_gt = axes[0, index-1]\n",
        "    ax_gt.imshow(gt_image)\n",
        "    ax_gt.axis('off')\n",
        "    ax_gt.set_title(f'GT {index}')\n",
        "\n",
        "    # Plot output image\n",
        "    ax_out = axes[1, index-1]\n",
        "    ax_out.imshow(out_image_1)\n",
        "    ax_out.axis('off')\n",
        "    ax_out.set_title(f'M1 {index}')\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "oIjNMs8XdVfj",
        "outputId": "5295ef2c-9707-42ef-bc3a-094a7b4ff48e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W-S7G9tWeSz8"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}