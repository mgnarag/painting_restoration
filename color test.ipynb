{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgnarag/painting_restoration/blob/main/color%20test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gXM5CNP5BaYU",
        "outputId": "7f9667f5-fc80-4b3a-a31c-3510bf56eb6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/My\\ Drive\n",
        "file_path = \"/content/drive/MyDrive/Baumgartner screenshots/\""
      ],
      "metadata": {
        "id": "xiAgOwvmBcjr",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing packages"
      ],
      "metadata": {
        "id": "zEoJQzJ5bM8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image, ImageOps\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import zoom\n",
        "\n",
        "import cv2\n",
        "from skimage import color\n",
        "\n",
        "from tensorflow import keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import PIL\n",
        "PIL.Image.MAX_IMAGE_PIXELS = 236958876\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "FgE9bH4-MFlB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining functions"
      ],
      "metadata": {
        "id": "ihq928NMbTBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rgb_lab_normalized(im):\n",
        "    rgb_array = np.array(im) # Convert to numpy array\n",
        "    rgb_array_normalized = rgb_array / 255.0 # Normalize RGB values from 0 to 1\n",
        "    lab_array_normalized = color.rgb2lab(rgb_array_normalized) # Convert RGB to LAB colorspace\n",
        "    lab_array_normalized[..., 0] = (lab_array_normalized[..., 0]) / 100.0 # Scale LAB values to range [0, 1]\n",
        "    lab_array_normalized[..., 1] = (lab_array_normalized[..., 1] + 128) / 255.0\n",
        "    lab_array_normalized[..., 2] = (lab_array_normalized[..., 2] + 128) / 255.0\n",
        "    lab_image_normalized = Image.fromarray((lab_array_normalized * 255).astype(np.uint8), mode='LAB')# Convert LAB array back to image\n",
        "    return lab_image_normalized"
      ],
      "metadata": {
        "id": "GRBwljTxNi-i"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Metric_scores = []\n",
        "\n",
        "groundtruth_folder_path = file_path+ \"Testing/portion only/color test gt/\"\n",
        "gt_files = sorted(os.listdir(groundtruth_folder_path))\n",
        "\n",
        "ground_truth = []\n",
        "for image_file in gt_files:\n",
        "    image_path = os.path.join(groundtruth_folder_path, image_file)\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    ground_truth.append(image)\n"
      ],
      "metadata": {
        "id": "SUCRmvIOCrJP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model"
      ],
      "metadata": {
        "id": "3lnB29-_cVp-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model RGB:**"
      ],
      "metadata": {
        "id": "EWPFTVoVxePF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_size = 8\n",
        "size = 8\n",
        "\n",
        "def rgb_L_ab(rgb_image, test_L):\n",
        "    lab_array = color.rgb2lab(np.array(rgb_image))# Convert RGB to LAB colorspace\n",
        "    lab_array[..., 0] = test_L #Change L channel to input\n",
        "    rgb_array = color.lab2rgb(lab_array)# Convert back LAB to RGB colorspace\n",
        "    rgb_array = (rgb_array*255).astype(np.uint8)# Scale RGB values back to the range [0, 255]\n",
        "    rgb_array = Image.fromarray(rgb_array, mode='RGB')# Convert RGB array back to image\n",
        "    return rgb_array\n",
        "\n",
        "autoencoder = keras.models.load_model(file_path + 'Model/portion only/unet_'+str(n_size)+'_rgb')\n",
        "\n",
        "input_folder_path = file_path+ \"Testing/portion only/color test/\"\n",
        "input_files = sorted(os.listdir(input_folder_path))\n",
        "\n",
        "for index, image_file in enumerate(input_files):\n",
        "    image_path = os.path.join(input_folder_path, image_file)\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    test_L = color.rgb2lab(np.array(image))\n",
        "    test_L = test_L[..., 0]\n",
        "    image = np.array(image).astype(np.float32) / 255.0# Convert image to numpy array and scale pixel values to [0, 1]\n",
        "    image = np.expand_dims(image, axis=0)# Expand dimensions to match the expected input shape (1, 8, 8, 3)\n",
        "\n",
        "    decoded_imgs = autoencoder.predict(image)\n",
        "    final = (decoded_imgs*255).astype('uint8')\n",
        "\n",
        "    #----------------TEST ON FULL RGB--------------------#\n",
        "    final_rgb = final\n",
        "    final_rgb = np.squeeze(final_rgb)\n",
        "    reconstructed_rgb = Image.fromarray(final_rgb)\n",
        "    reconstructed_rgb.save(file_path + \"Testing/portion only/color test out/\"+\"Method_1_\"+image_file)\n",
        "\n",
        "\n",
        "    #plt.figure(), plt.imshow(reconstructed_rgb)\n",
        "\n",
        "    #----------------TEST ON L from input and AB from convert RGB2LAB of model--------------------#\n",
        "    final_lab = rgb_L_ab(final_rgb, test_L)\n",
        "    final_lab = np.squeeze(final_lab)\n",
        "    reconstructed_lab = Image.fromarray(final_lab)\n",
        "    reconstructed_lab.save(file_path + \"Testing/portion only/color test out/\"+\"Method_2_\"+image_file)\n",
        "    #plt.figure(), plt.imshow(reconstructed_lab)"
      ],
      "metadata": {
        "id": "y3j1v9uGdbTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a55d7a4b-233c-4aad-eb53-67f2ee5b5401"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model LAB:**"
      ],
      "metadata": {
        "id": "kvODWjVrxmRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import PIL\n",
        "PIL.Image.MAX_IMAGE_PIXELS = 236958876\n",
        "\n",
        "n_size = 8\n",
        "size = n_size\n",
        "\n",
        "def lab_rgb_unnormalized(lab_image):\n",
        "    lab_array = np.array(lab_image/255)# Convert LAB image to numpy array\n",
        "    lab_array[..., 0] = lab_array[..., 0] * 100.0# Scale LAB values back to their original ranges\n",
        "    lab_array[..., 1] = (lab_array[..., 1] * 255.0) - 128\n",
        "    lab_array[..., 2] = (lab_array[..., 2] * 255.0) - 128\n",
        "    rgb_array_unnormalized = color.lab2rgb(lab_array)# Convert LAB to RGB colorspace\n",
        "    rgb_array_unnormalized = (rgb_array_unnormalized * 255).astype(np.uint8)# Scale RGB values back to the range [0, 255]\n",
        "    rgb_image_unnormalized = Image.fromarray(rgb_array_unnormalized, mode='RGB')# Convert RGB array back to image\n",
        "    return rgb_image_unnormalized\n",
        "\n",
        "def AB_rgb_unnormalized(lab_image, test_L):\n",
        "    lab_array = np.array(lab_image/255)# Convert LAB image to numpy array\n",
        "    lab_array[..., 0] = test_L #replacing L from the original input\n",
        "    lab_array[..., 1] = (lab_array[..., 1] * 255.0) - 128\n",
        "    lab_array[..., 2] = (lab_array[..., 2] * 255.0) - 128\n",
        "    rgb_array_unnormalized = color.lab2rgb(lab_array)# Convert LAB to RGB colorspace\n",
        "    rgb_array_unnormalized = (rgb_array_unnormalized * 255).astype(np.uint8)# Scale RGB values back to the range [0, 255]\n",
        "    rgb_image_unnormalized = Image.fromarray(rgb_array_unnormalized, mode='RGB')# Convert RGB array back to image\n",
        "    return rgb_image_unnormalized\n",
        "\n",
        "\n",
        "autoencoder = keras.models.load_model(file_path + 'Model/portion only/unet_'+str(n_size)+'_lab')\n",
        "\n",
        "input_folder_path = file_path+ \"Testing/portion only/color test/\"\n",
        "input_files = sorted(os.listdir(input_folder_path))\n",
        "\n",
        "for index, image_file in enumerate(input_files):\n",
        "    image_path = os.path.join(input_folder_path, image_file)\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    test_L = color.rgb2lab(np.array(image))\n",
        "    test_L = test_L[..., 0]\n",
        "    image = rgb_lab_normalized(image)\n",
        "    image = np.array(image).astype(np.float32) / 255.0# Convert image to numpy array and scale pixel values to [0, 1]\n",
        "    image = np.expand_dims(image, axis=0)# Expand dimensions to match the expected input shape (1, 8, 8, 3)\n",
        "\n",
        "    decoded_imgs = autoencoder.predict(image)\n",
        "    final = (decoded_imgs*255).astype('uint8')\n",
        "\n",
        "    #----------------TEST ON FULL LAB--------------------#\n",
        "    final_LAB = lab_rgb_unnormalized(np.squeeze(final))\n",
        "    final_LAB = np.squeeze(final_LAB)\n",
        "    reconstructed_LAB = Image.fromarray(final_LAB)\n",
        "    reconstructed_LAB.save(file_path + \"Testing/portion only/\"+\"Method_3_\"+image_file)\n",
        "    #plt.figure(), plt.imshow(reconstructed_LAB)\n",
        "\n",
        "    #----------------TEST ON L from input and AB from model--------------------#\n",
        "    final_L_AB = AB_rgb_unnormalized(np.squeeze(final), test_L)\n",
        "    final_L_AB = np.squeeze(final_L_AB)\n",
        "    reconstructed_L_AB = Image.fromarray(final_L_AB)\n",
        "    reconstructed_L_AB.save(file_path + \"Testing/portion only/\"+\"Method_4_\"+image_file)\n",
        "    #plt.figure(), plt.imshow(reconstructed_L_AB)"
      ],
      "metadata": {
        "id": "l2WOweoWxWeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model AB**"
      ],
      "metadata": {
        "id": "2ij1l4JRyQ3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import PIL\n",
        "PIL.Image.MAX_IMAGE_PIXELS = 236958876\n",
        "\n",
        "n_size = 8\n",
        "size = n_size\n",
        "\n",
        "def rgb_lab_normalized(im):\n",
        "    rgb_array = np.array(im) # Convert to numpy array\n",
        "    rgb_array_normalized = rgb_array / 255.0 # Normalize RGB values from 0 to 1\n",
        "    lab_array_normalized = color.rgb2lab(rgb_array_normalized) # Convert RGB to LAB colorspace\n",
        "    lab_array_normalized[..., 0] = (lab_array_normalized[..., 0]) / 100.0 # Scale LAB values to range [0, 1]\n",
        "    lab_array_normalized[..., 1] = (lab_array_normalized[..., 1] + 128) / 255.0\n",
        "    lab_array_normalized[..., 2] = (lab_array_normalized[..., 2] + 128) / 255.0\n",
        "    lab_image_normalized = Image.fromarray((lab_array_normalized * 255).astype(np.uint8), mode='LAB')# Convert LAB array back to image\n",
        "    return lab_image_normalized\n",
        "\n",
        "def AB_rgb_unnormalized(ab_image, test_L):\n",
        "    ab_array = np.array(ab_image)/255# Convert LAB image to numpy array\n",
        "    ab_array[..., 0] = (ab_array[..., 0] * 255.0) - 128\n",
        "    ab_array[..., 1] = (ab_array[..., 1] * 255.0) - 128\n",
        "    LAB_array = np.dstack((test_L, ab_array[:,:,0], ab_array[:,:,1]))\n",
        "    rgb_array_unnormalized = color.lab2rgb(LAB_array)# Convert LAB to RGB colorspace\n",
        "    rgb_array_unnormalized = (rgb_array_unnormalized * 255).astype(np.uint8)# Scale RGB values back to the range [0, 255]\n",
        "    rgb_image_unnormalized = Image.fromarray(rgb_array_unnormalized, mode='RGB')# Convert RGB array back to image\n",
        "    return rgb_image_unnormalized\n",
        "\n",
        "def crop_(im):\n",
        "    width, height = im.size\n",
        "    data = []\n",
        "    for j in range(0,int(height/n_size)):\n",
        "        for i in range(0,int(width/n_size)):\n",
        "            im1 = im.crop((0 + (n_size*i), 0 + (n_size*j), n_size + (n_size*i), n_size + (n_size*j)))\n",
        "            im1 = np.array(im1)\n",
        "            im1 = im1.astype(np.float32)\n",
        "            data.append(im1)\n",
        "    return data\n",
        "\n",
        "autoencoder = keras.models.load_model(file_path + 'Model/portion only/unet_'+str(n_size)+'_ab')\n",
        "\n",
        "input_folder_path = file_path+ \"Testing/portion only/color test/\"\n",
        "input_files = sorted(os.listdir(input_folder_path))\n",
        "\n",
        "for index, image_file in enumerate(input_files):\n",
        "    image_path = os.path.join(input_folder_path, image_file)\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    test_L = color.rgb2lab(np.array(image))\n",
        "    test_L = np.array(test_L[..., 0]).astype('uint8')\n",
        "    image = rgb_lab_normalized(image)\n",
        "    image = np.array(image).astype(np.float32) / 255.0# Convert image to numpy array and scale pixel values to [0, 1]\n",
        "    image = np.expand_dims(image, axis=0)# Expand dimensions to match the expected input shape (1, 8, 8, 3)\n",
        "\n",
        "    decoded_imgs = autoencoder.predict(image[:,:,:,1:3])\n",
        "    final = (decoded_imgs*255).astype('uint8')\n",
        "\n",
        "    #----------------TEST ON L from input and AB from model--------------------#\n",
        "    final_L_AB = AB_rgb_unnormalized(final, test_L)\n",
        "    final_L_AB = final_L_AB\n",
        "    reconstructed_L_AB = Image.fromarray(final_L_AB)\n",
        "    reconstructed_L_AB.save(file_path + \"Testing/portion only/\"+\"Method_5_\"+image_file)\n",
        "    #plt.figure(), plt.imshow(reconstructed_L_AB)"
      ],
      "metadata": {
        "id": "jrXxXGj5yFs3",
        "outputId": "c41baddf-2235-49b8-db98-693f266a4db1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 165ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 8 and the array at index 1 has size 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-399d92873848>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m#----------------TEST ON L from input and AB from model--------------------#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mfinal_L_AB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAB_rgb_unnormalized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_L\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mfinal_L_AB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_L_AB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mreconstructed_L_AB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_L_AB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-399d92873848>\u001b[0m in \u001b[0;36mAB_rgb_unnormalized\u001b[0;34m(ab_image, test_L)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mab_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mab_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mab_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mab_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mLAB_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_L\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mab_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mab_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mrgb_array_unnormalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlab2rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLAB_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# Convert LAB to RGB colorspace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mrgb_array_unnormalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrgb_array_unnormalized\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# Scale RGB values back to the range [0, 255]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mdstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 8 and the array at index 1 has size 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model AB plus Model L**"
      ],
      "metadata": {
        "id": "EzOXFu1uyjLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import PIL\n",
        "PIL.Image.MAX_IMAGE_PIXELS = 236958876\n",
        "\n",
        "n_size = 32\n",
        "size = 32\n",
        "\n",
        "def rgb_lab_normalized(im):\n",
        "    rgb_array = np.array(im) # Convert to numpy array\n",
        "    rgb_array_normalized = rgb_array / 255.0 # Normalize RGB values from 0 to 1\n",
        "    lab_array_normalized = color.rgb2lab(rgb_array_normalized) # Convert RGB to LAB colorspace\n",
        "    lab_array_normalized[..., 0] = (lab_array_normalized[..., 0]) / 100.0 # Scale LAB values to range [0, 1]\n",
        "    lab_array_normalized[..., 1] = (lab_array_normalized[..., 1] + 128) / 255.0\n",
        "    lab_array_normalized[..., 2] = (lab_array_normalized[..., 2] + 128) / 255.0\n",
        "    lab_image_normalized = Image.fromarray((lab_array_normalized * 255).astype(np.uint8), mode='LAB')# Convert LAB array back to image\n",
        "    return lab_image_normalized\n",
        "\n",
        "def L_AB_rgb_unnormalized(ab_image, final_L):\n",
        "    ab_image = ab_image/255.0\n",
        "    final_L = final_L/255.0\n",
        "    final_L[..., 0] = final_L[..., 0]*100.0\n",
        "    ab_image[..., 0] = (ab_image[..., 0] * 255.0) - 128\n",
        "    ab_image[..., 1] = (ab_image[..., 1] * 255.0) - 128\n",
        "    LAB_array = np.dstack((final_L, ab_image[:,:,0], ab_image[:,:,1]))\n",
        "    rgb_array_unnormalized = color.lab2rgb(LAB_array)# Convert LAB to RGB colorspace\n",
        "    rgb_array_unnormalized = (rgb_array_unnormalized * 255).astype(np.uint8)# Scale RGB values back to the range [0, 255]\n",
        "    rgb_image_unnormalized = Image.fromarray(rgb_array_unnormalized, mode='RGB')# Convert RGB array back to image\n",
        "    return rgb_image_unnormalized\n",
        "\n",
        "def crop_(im):\n",
        "    width, height = im.size\n",
        "    data = []\n",
        "    for j in range(0,int(height/n_size)):\n",
        "        for i in range(0,int(width/n_size)):\n",
        "            im1 = im.crop((0 + (n_size*i), 0 + (n_size*j), n_size + (n_size*i), n_size + (n_size*j)))\n",
        "            im1 = np.array(im1)\n",
        "            im1 = im1.astype(np.float32)\n",
        "            data.append(im1)\n",
        "    return data\n",
        "\n",
        "\n",
        "#----------------READING THE TEST IMAGE--------------------#\n",
        "test = Image.open(file_path+ \"Testing/\" + filename).convert('RGB')\n",
        "test = rgb_lab_normalized(test)\n",
        "w_dirty, h_dirty = test.size\n",
        "#----------------------------------------------------------#\n",
        "\n",
        "#----------------GETTING AB--------------------#\n",
        "autoencoder = keras.models.load_model(file_path + 'Model/unet_'+str(n_size)+'_ab')\n",
        "\n",
        "xx = int(w_dirty/n_size)\n",
        "final=[]\n",
        "for portion in range(0,xx):\n",
        "    im1 = test.crop((n_size*portion, 0, (n_size*portion) + n_size, h_dirty))\n",
        "    w1, h1 = im1.size\n",
        "    w = int(w1/n_size)\n",
        "    h = int(h1/n_size)\n",
        "    neverbeforeseen = np.array(crop_(im1))\n",
        "    neverbeforeseen = neverbeforeseen[:,:,:,1:3]\n",
        "    neverbeforeseen = np.array(neverbeforeseen).astype(np.float32)/255.0\n",
        "    decoded_imgs = autoencoder.predict(neverbeforeseen)\n",
        "    col = np.vstack((decoded_imgs[0],decoded_imgs[1]))\n",
        "    for i in range(2,h):\n",
        "        col = np.vstack((col,decoded_imgs[i]))\n",
        "    y = col\n",
        "    y = (y * 255).astype('uint8')\n",
        "    if portion == 0:\n",
        "        final = y\n",
        "    if portion > 0:\n",
        "        final = np.hstack((final,y))\n",
        "\n",
        "#----------------GETTING L--------------------#\n",
        "autoencoder = keras.models.load_model(file_path + 'Model/unet_'+str(n_size)+'_L')\n",
        "\n",
        "final_L=[]\n",
        "for portion in range(0,xx):\n",
        "    im1 = test.crop((n_size*portion, 0, (n_size*portion) + n_size, h_dirty))\n",
        "    w1, h1 = im1.size\n",
        "    w = int(w1/n_size)\n",
        "    h = int(h1/n_size)\n",
        "    neverbeforeseen = np.array(crop_(im1))\n",
        "    neverbeforeseen = neverbeforeseen[:,:,:,0:1]\n",
        "    neverbeforeseen = np.array(neverbeforeseen).astype(np.float32)/255.0\n",
        "    decoded_imgs = autoencoder.predict(neverbeforeseen)\n",
        "    col = np.vstack((decoded_imgs[0],decoded_imgs[1]))\n",
        "    for i in range(2,h):\n",
        "        col = np.vstack((col,decoded_imgs[i]))\n",
        "    y = col\n",
        "    y = (y * 255).astype('uint8')\n",
        "    if portion == 0:\n",
        "        final_L = y\n",
        "    if portion > 0:\n",
        "        final_L = np.hstack((final_L,y))\n",
        "\n",
        "#----------------TEST ON L from model and AB from model--------------------#\n",
        "final_L_AB = L_AB_rgb_unnormalized(final, final_L)\n",
        "final_L_AB = np.squeeze(final_L_AB)\n",
        "reconstructed_L_AB = Image.fromarray(final_L_AB)\n",
        "reconstructed_L_AB.save(file_path + \"Testing/\"+\"Method_6_\"+filename)\n",
        "plt.figure(), plt.imshow(reconstructed_L_AB)"
      ],
      "metadata": {
        "id": "LTH18YqyypPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## COMPUTE SSIM SCORES"
      ],
      "metadata": {
        "id": "qo3xeQtXwVif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Function to open image and convert to numpy array\n",
        "def load_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')  # Ensure image is in RGB mode\n",
        "    return np.array(image)\n",
        "\n",
        "image_path1 = file_path + 'Testing/OUTPUT_[05] Comprimise-d.png'\n",
        "image_path2 = file_path + \"Testing/\"+\"Method_3_\"+str(size)+\"LAB_\"+filename\n",
        "\n",
        "# Load images\n",
        "image1 = load_image(image_path1)\n",
        "image2 = load_image(image_path2)\n",
        "\n",
        "# Ensure the images have the same dimensions\n",
        "if image1.shape != image2.shape:\n",
        "    raise ValueError(\"Input images must have the same dimensions.\")\n",
        "\n",
        "# Compute SSIM for each channel and average the results\n",
        "ssim_index_r = ssim(image1[:, :, 0], image2[:, :, 0], data_range=image1[:, :, 0].max() - image1[:, :, 0].min())\n",
        "ssim_index_g = ssim(image1[:, :, 1], image2[:, :, 1], data_range=image1[:, :, 1].max() - image1[:, :, 1].min())\n",
        "ssim_index_b = ssim(image1[:, :, 2], image2[:, :, 2], data_range=image1[:, :, 2].max() - image1[:, :, 2].min())\n",
        "\n",
        "ssim_index_rgb = (ssim_index_r + ssim_index_g + ssim_index_b) / 3\n",
        "\n",
        "print(f\"SSIM for R channel: {ssim_index_r}\")\n",
        "print(f\"SSIM for G channel: {ssim_index_g}\")\n",
        "print(f\"SSIM for B channel: {ssim_index_b}\")\n",
        "print(f\"Average SSIM for RGB image(Method3): {ssim_index_rgb}\")\n"
      ],
      "metadata": {
        "id": "MHIfhhpLHwNf",
        "outputId": "627c1f49-a23a-4e21-e02f-23c909e3a196",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SSIM for R channel: 0.509358346147561\n",
            "SSIM for G channel: 0.5081811788128479\n",
            "SSIM for B channel: 0.4024215496836909\n",
            "Average SSIM for RGB image(Method3): 0.4733203582146999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Function to open image and convert to numpy array\n",
        "def load_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')  # Ensure image is in RGB mode\n",
        "    return np.array(image)\n",
        "\n",
        "image_path1 = file_path + 'Testing/OUTPUT_[05] Comprimise-d.png'\n",
        "image_path2 = file_path + \"Testing/\"+\"Method_4_\"+str(size)+\"L_AB_\"+filename\n",
        "\n",
        "# Load images\n",
        "image1 = load_image(image_path1)\n",
        "image2 = load_image(image_path2)\n",
        "\n",
        "# Ensure the images have the same dimensions\n",
        "if image1.shape != image2.shape:\n",
        "    raise ValueError(\"Input images must have the same dimensions.\")\n",
        "\n",
        "# Compute SSIM for each channel and average the results\n",
        "ssim_index_r = ssim(image1[:, :, 0], image2[:, :, 0], data_range=image1[:, :, 0].max() - image1[:, :, 0].min())\n",
        "ssim_index_g = ssim(image1[:, :, 1], image2[:, :, 1], data_range=image1[:, :, 1].max() - image1[:, :, 1].min())\n",
        "ssim_index_b = ssim(image1[:, :, 2], image2[:, :, 2], data_range=image1[:, :, 2].max() - image1[:, :, 2].min())\n",
        "\n",
        "ssim_index_rgb = (ssim_index_r + ssim_index_g + ssim_index_b) / 3\n",
        "\n",
        "print(f\"SSIM for R channel: {ssim_index_r}\")\n",
        "print(f\"SSIM for G channel: {ssim_index_g}\")\n",
        "print(f\"SSIM for B channel: {ssim_index_b}\")\n",
        "print(f\"Average SSIM for RGB image(Method4): {ssim_index_rgb}\")\n"
      ],
      "metadata": {
        "id": "K_XXHvyDNokf",
        "outputId": "cd917983-a029-457c-ba09-72d2993273bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SSIM for R channel: 0.5487580309946481\n",
            "SSIM for G channel: 0.5692294383749303\n",
            "SSIM for B channel: 0.4253035732161732\n",
            "Average SSIM for RGB image(Method4): 0.514430347528584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "def compute_average_ssim(image1_path, image2_path):\n",
        "    # Open the images using Pillow\n",
        "    image1 = Image.open(image1_path).convert('RGB')\n",
        "    image2 = Image.open(image2_path).convert('RGB')\n",
        "\n",
        "    # Convert images from RGB to LAB color space using Pillow\n",
        "    lab_image1 = image1.convert('LAB')\n",
        "    lab_image2 = image2.convert('LAB')\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    lab_image1 = np.array(lab_image1)\n",
        "    lab_image2 = np.array(lab_image2)\n",
        "\n",
        "    # Extract the A and B channels\n",
        "    a_channel1, b_channel1 = lab_image1[:, :, 1], lab_image1[:, :, 2]\n",
        "    a_channel2, b_channel2 = lab_image2[:, :, 1], lab_image2[:, :, 2]\n",
        "\n",
        "    # Compute SSIM for the A channel\n",
        "    ssim_a = ssim(a_channel1, a_channel2)\n",
        "\n",
        "    # Compute SSIM for the B channel\n",
        "    ssim_b = ssim(b_channel1, b_channel2)\n",
        "\n",
        "    # Average the SSIM values\n",
        "    average_ssim = (ssim_a + ssim_b) / 2\n",
        "\n",
        "    return average_ssim\n",
        "\n",
        "# Paths to the images\n",
        "image1_path = file_path + 'Testing/OUTPUT_[05] Comprimise-d.png'\n",
        "image2_path = image_path2 = file_path + \"Testing/\"+\"Method_3_\"+str(size)+\"LAB_\"+filename\n",
        "\n",
        "# Compute the average SSIM\n",
        "average_ssim_value = compute_average_ssim(image1_path, image2_path)\n",
        "print(f\"Average SSIM (A and B channels (Method3)): {average_ssim_value}\")\n"
      ],
      "metadata": {
        "id": "FK867a9sNxwM",
        "outputId": "be49afbb-ce9c-40c9-c7e1-7a32b21e2081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average SSIM (A and B channels (Method3)): 0.4829091381886401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "def compute_average_ssim(image1_path, image2_path):\n",
        "    # Open the images using Pillow\n",
        "    image1 = Image.open(image1_path).convert('RGB')\n",
        "    image2 = Image.open(image2_path).convert('RGB')\n",
        "\n",
        "    # Convert images from RGB to LAB color space using Pillow\n",
        "    lab_image1 = image1.convert('LAB')\n",
        "    lab_image2 = image2.convert('LAB')\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    lab_image1 = np.array(lab_image1)\n",
        "    lab_image2 = np.array(lab_image2)\n",
        "\n",
        "    # Extract the A and B channels\n",
        "    a_channel1, b_channel1 = lab_image1[:, :, 1], lab_image1[:, :, 2]\n",
        "    a_channel2, b_channel2 = lab_image2[:, :, 1], lab_image2[:, :, 2]\n",
        "\n",
        "    # Compute SSIM for the A channel\n",
        "    ssim_a = ssim(a_channel1, a_channel2)\n",
        "\n",
        "    # Compute SSIM for the B channel\n",
        "    ssim_b = ssim(b_channel1, b_channel2)\n",
        "\n",
        "    # Average the SSIM values\n",
        "    average_ssim = (ssim_a + ssim_b) / 2\n",
        "\n",
        "    return average_ssim\n",
        "\n",
        "# Paths to the images\n",
        "image1_path = file_path + 'Testing/OUTPUT_[05] Comprimise-d.png'\n",
        "image2_path = image_path2 = file_path + \"Testing/\"+\"Method_4_\"+str(size)+\"L_AB_\"+filename\n",
        "\n",
        "# Compute the average SSIM\n",
        "average_ssim_value = compute_average_ssim(image1_path, image2_path)\n",
        "print(f\"Average SSIM (A and B channels (Method4)): {average_ssim_value}\")\n"
      ],
      "metadata": {
        "id": "HJJHBbh3SHZO",
        "outputId": "968b80df-3f0f-4714-83ad-270f209f7aad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average SSIM (A and B channels (Method4)): 0.4836187382989704\n"
          ]
        }
      ]
    }
  ]
}