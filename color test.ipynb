{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgnarag/painting_restoration/blob/main/color%20test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gXM5CNP5BaYU",
        "outputId": "e57a504b-d9f6-4d55-fe24-916fb676f730",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/My\\ Drive\n",
        "file_path = \"/content/drive/MyDrive/Baumgartner screenshots/\""
      ],
      "metadata": {
        "id": "xiAgOwvmBcjr",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "424a02b7-09d5-452d-d1e2-cac6d75a0dd7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1872_Mindanao_NAP_D.FedericoCaballero.tif\n",
            " 1885_Mactan_NAP_FelixPelayo.tiff\n",
            " 201464423-23022858-PaymentSlip.pdf\n",
            " 313490484_646790150357239_663796780442369775_n.jpg\n",
            " 361079911_248325231393045_2145216296096417082_n.jpg\n",
            "'Applied Physics 184 FX-2'\n",
            " Architectural_designs\n",
            " autoencoder_32\n",
            "'autoencoder_32 (1)'\n",
            " autoencoder_64\n",
            "'Baumgartner screenshots'\n",
            "'BS Applied Physics'\n",
            " Classroom\n",
            "'CLEAN128_TEST_INPUT_[04] Coming into Bloom.png'\n",
            "'CLEAN_[WB] 1872_Mindanao_NAP_D (1).FedericoCaballero.tif'\n",
            "'CLEAN_[WB] 1872_Mindanao_NAP_D (2).FedericoCaballero.tif'\n",
            "'CLEAN_[WB] 1872_Mindanao_NAP_D (3).FedericoCaballero.tif'\n",
            "'CLEAN_[WB] 1872_Mindanao_NAP_D.FedericoCaballero.tif'\n",
            "'CNN scores.gsheet'\n",
            "'Colab Notebooks'\n",
            "'CONSENT_NARAG_MARK JEREMY_G.pdf'\n",
            " CONSENT_NARAG_MARKJEREMY_G.pdf\n",
            " CS284\n",
            "'Dorm bill.png'\n",
            " Fast-Dreambooth\n",
            "'fingerprint (1).pb'\n",
            "'fingerprint (2).pb'\n",
            "'fingerprint (3).pb'\n",
            " fingerprint.pb\n",
            " FN.png\n",
            " FP.png\n",
            " GAN\n",
            "'Geology (Ate Grass)'\n",
            "'Getting started.pdf'\n",
            " image.jpg\n",
            " IMG_5032.jpeg\n",
            " IMG_6546.PNG\n",
            "'IMG_9359 (1).PNG'\n",
            " IMG_9359.PNG\n",
            "'Information Sharing Consent Form - NARAG.pdf'\n",
            "'Information Sharing Consent Form.pdf'\n",
            " Jem_face\n",
            " Jem_face_2\n",
            " Jem_facemetadata.jsonl\n",
            "'[Journal of Cultural Heritage] Discovering artistic influences of painters'\n",
            " LORA\n",
            "'loss_32 (1).csv'\n",
            " loss_32.csv\n",
            "'loss_64 (1).csv'\n",
            " loss_64.csv\n",
            "'MALIPOL_CHAE ANN.pdf'\n",
            "'March 13 2024 Pigment Reflectance.gsheet'\n",
            "'Metric_100DPI_white balanced and bw output_1.csv'\n",
            "'Model_1_TEST_INPUT_[05] Comprimise-d.png'\n",
            "'Model_2_TEST_INPUT_[04] Coming into Bloom_V1.png'\n",
            "'Model_2_TEST_INPUT_[05] Comprimise-d.png'\n",
            "'model 64'\n",
            "'model grayscale output'\n",
            "'MS PHYSICS'\n",
            "'MS Thesis videos'\n",
            "'NARAG, MARK JEREMY, GACIAS.gdoc'\n",
            "'NARAG, MARK JEREMY, GACIAS.pdf'\n",
            "'NARAG, MARK JEREMY.jpg'\n",
            " NIP_Narag_MarkJeremy_Consent.pdf\n",
            " NIP_Narag_MarkJeremy_Informal.jpg\n",
            " NIP_Narag_MarkJeremy_Sablay.jpg\n",
            "'output v1_blue (1).png'\n",
            "'output v1_blue.png'\n",
            "'output v1_gray (1).png'\n",
            "'output v1_gray.png'\n",
            "'output v1_green (1).png'\n",
            "'output v1_green.png'\n",
            "'output v1_red (1).png'\n",
            "'output v1_red.png'\n",
            "'output v1_RGB (1).png'\n",
            "'output v1_RGB_GRAY (1).png'\n",
            "'output v1_RGB_GRAY.png'\n",
            "'output v1_RGB.png'\n",
            "'output v2_blue (1).png'\n",
            "'output v2_blue.png'\n",
            "'output v2_gray (1).png'\n",
            "'output v2_gray.png'\n",
            "'output v2_green (1).png'\n",
            "'output v2_green.png'\n",
            "'output v2_red (1).png'\n",
            "'output v2_red.png'\n",
            "'output v2_RGB (1).png'\n",
            "'output v2_RGB_GRAY (1).png'\n",
            "'output v2_RGB_GRAY.png'\n",
            "'output v2_RGB.png'\n",
            "'output v3_blue (1).png'\n",
            "'output v3_blue.png'\n",
            "'output v3_gray (1).png'\n",
            "'output v3_gray.png'\n",
            "'output v3_green (1).png'\n",
            "'output v3_green.png'\n",
            "'output v3_red (1).png'\n",
            "'output v3_red.png'\n",
            "'output v3_RGB (1).png'\n",
            "'output v3_RGB_GRAY (1).png'\n",
            "'output v3_RGB_GRAY.png'\n",
            "'output v3_RGB.png'\n",
            "'output v4_blue (1).png'\n",
            "'output v4_blue.png'\n",
            "'output v4_gray (1).png'\n",
            "'output v4_gray.png'\n",
            "'output v4_green (1).png'\n",
            "'output v4_green.png'\n",
            "'output v4_red (1).png'\n",
            "'output v4_red.png'\n",
            "'output v4_RGB (1).png'\n",
            "'output v4_RGB_GRAY (1).png'\n",
            "'output v4_RGB_GRAY.png'\n",
            "'output v4_RGB.png'\n",
            "'output v5_blue (1).png'\n",
            "'output v5_blue.png'\n",
            "'output v5_gray (1).png'\n",
            "'output v5_gray.png'\n",
            "'output v5_green (1).png'\n",
            "'output v5_green.png'\n",
            "'output v5_red (1).png'\n",
            "'output v5_red.png'\n",
            "'output v5_RGB (1).png'\n",
            "'output v5_RGB_GRAY (1).png'\n",
            "'output v5_RGB_GRAY.png'\n",
            "'output v5_RGB.png'\n",
            "'output v6_blue (1).png'\n",
            "'output v6_blue.png'\n",
            "'output v6_gray (1).png'\n",
            "'output v6_gray.png'\n",
            "'output v6_green (1).png'\n",
            "'output v6_green.png'\n",
            "'output v6_red.png'\n",
            "'output v6_RGB (1).png'\n",
            "'output v6_RGB_GRAY (1).png'\n",
            "'output v6_RGB_GRAY.png'\n",
            "'output v6_RGB.png'\n",
            "'PEHA 2021 Consent Form (fillable).pdf'\n",
            "'PhD PHYSICS'\n",
            "'PHOTO_NARAG_MARK JEREMY_G.jpg'\n",
            " PHOTO_NARAG_MARKJEREMY_G.jpg\n",
            "'Physics 265'\n",
            "'Physics 301 2S AY2122'\n",
            "'Physics 305 Data Driven Astronomy'\n",
            "'Research files'\n",
            "'RESUME_Mark Jeremy Narag.pdf'\n",
            " Rizal_input.png\n",
            "'Sanyata journal'\n",
            "'saved_model (1).pb'\n",
            "'saved_model (2).pb'\n",
            "'saved_model (3).pb'\n",
            " saved_model.pb\n",
            "'Screen Shot 2022-08-31 at 10.46.42.png'\n",
            "'Screen Shot 2022-09-13 at 12.40.21.png'\n",
            "'Screen Shot 2022-09-13 at 12.43.14.png'\n",
            " sd\n",
            "'SPP 2022'\n",
            " TP.png\n",
            " unet_64\n",
            "'Untitled document.gdoc'\n",
            "'UP CRS - Outstanding Transactions.pdf'\n",
            "'Vaccination Card (1).jpg'\n",
            "'Vaccination Card.jpg'\n",
            "'val_loss_32 (1).csv'\n",
            " val_loss_32.csv\n",
            "'val_loss_64 (1).csv'\n",
            " val_loss_64.csv\n",
            "'variables (1).data-00000-of-00001'\n",
            "'variables (2).data-00000-of-00001'\n",
            "'variables (3).data-00000-of-00001'\n",
            " variables.data-00000-of-00001\n",
            "'[WB] 1872_Mindanao_NAP_D.FedericoCaballero.tif'\n",
            "'[WB] 1885_Mactan_NAP_FelixPelayo.png'\n",
            "'[WB] XXXX_Cagayan y Ilocos_online.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing packages"
      ],
      "metadata": {
        "id": "zEoJQzJ5bM8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image, ImageOps\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import zoom\n",
        "\n",
        "import cv2\n",
        "from skimage import color\n",
        "\n",
        "from tensorflow import keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import PIL\n",
        "PIL.Image.MAX_IMAGE_PIXELS = 236958876\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "FgE9bH4-MFlB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining functions"
      ],
      "metadata": {
        "id": "ihq928NMbTBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rgb_lab_normalized(im):\n",
        "    rgb_array = np.array(im) # Convert to numpy array\n",
        "    rgb_array_normalized = rgb_array / 255.0 # Normalize RGB values from 0 to 1\n",
        "    lab_array_normalized = color.rgb2lab(rgb_array_normalized) # Convert RGB to LAB colorspace\n",
        "    lab_array_normalized[..., 0] = (lab_array_normalized[..., 0]) / 100.0 # Scale LAB values to range [0, 1]\n",
        "    lab_array_normalized[..., 1] = (lab_array_normalized[..., 1] + 128) / 255.0\n",
        "    lab_array_normalized[..., 2] = (lab_array_normalized[..., 2] + 128) / 255.0\n",
        "    lab_image_normalized = Image.fromarray((lab_array_normalized * 255).astype(np.uint8), mode='LAB')# Convert LAB array back to image\n",
        "    return lab_image_normalized"
      ],
      "metadata": {
        "id": "GRBwljTxNi-i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model"
      ],
      "metadata": {
        "id": "3lnB29-_cVp-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model RGB:**"
      ],
      "metadata": {
        "id": "EWPFTVoVxePF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_size = 8\n",
        "size = 8\n",
        "\n",
        "def rgb_L_ab(rgb_image, test_L):\n",
        "    lab_array = color.rgb2lab(np.array(rgb_image))# Convert RGB to LAB colorspace\n",
        "    lab_array[..., 0] = test_L #Change L channel to input\n",
        "    rgb_array = color.lab2rgb(lab_array)# Convert back LAB to RGB colorspace\n",
        "    rgb_array = (rgb_array*255).astype(np.uint8)# Scale RGB values back to the range [0, 255]\n",
        "    rgb_array = Image.fromarray(rgb_array, mode='RGB')# Convert RGB array back to image\n",
        "    return rgb_array\n",
        "\n",
        "autoencoder = keras.models.load_model(file_path + 'Model/portion only/unet_'+str(n_size)+'_rgb')\n",
        "\n",
        "input_folder_path = file_path+ \"Testing/portion only/color test/\"\n",
        "input_files = sorted(os.listdir(input_folder_path))\n",
        "\n",
        "for image_file in input_files:\n",
        "    image_path = os.path.join(input_folder_path, image_file)\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    test_L = color.rgb2lab(np.array(image))\n",
        "    test_L = test_L[..., 0]\n",
        "    # Resize image to (8, 8) if not already\n",
        "    image = image.resize((8, 8))\n",
        "\n",
        "    # Convert image to numpy array and scale pixel values to [0, 1]\n",
        "    image = np.array(image).astype(np.float32) / 255.0\n",
        "\n",
        "    # Expand dimensions to match the expected input shape (1, 8, 8, 3)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(np.squeeze(image))  # Remove batch dimension for display\n",
        "    plt.show()\n",
        "\n",
        "    decoded_imgs = autoencoder.predict(image)\n",
        "    final = (decoded_imgs*255).astype('uint8')\n",
        "\n",
        "    #----------------TEST ON FULL RGB--------------------#\n",
        "    final_rgb = final\n",
        "    final_rgb = np.squeeze(final_rgb)\n",
        "    reconstructed_rgb = Image.fromarray(final_rgb)\n",
        "    reconstructed_rgb.save(file_path + \"Testing/portion only/color test out/\"+\"Method_1_\"+image_file)\n",
        "    plt.figure(), plt.imshow(reconstructed_rgb)\n",
        "\n",
        "    #----------------TEST ON L from input and AB from convert RGB2LAB of model--------------------#\n",
        "    final_lab = rgb_L_ab(final, test_L)\n",
        "    final_lab = np.squeeze(final_lab)\n",
        "    reconstructed_lab = Image.fromarray(final_lab)\n",
        "    reconstructed_lab.save(file_path + \"Testing/portion only/color test out/\"+\"Method_2_\"+image_file)\n",
        "    plt.figure(), plt.imshow(reconstructed_lab)"
      ],
      "metadata": {
        "id": "y3j1v9uGdbTb",
        "outputId": "e6e2137b-41c2-41e8-9cf4-352f9120a89f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 56ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/Baumgartner screenshots/Testing/portion only/color test out/Method_1_1_input.png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-8ebaf5da118d>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mfinal_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_rgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mreconstructed_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_rgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mreconstructed_rgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Testing/portion only/color test out/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"Method_1_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstructed_rgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2426\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2427\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2428\u001b[0;31m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2430\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Baumgartner screenshots/Testing/portion only/color test out/Method_1_1_input.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(final_rgb)"
      ],
      "metadata": {
        "id": "Xvz2MZvj_NDQ",
        "outputId": "74549b9d-0189-4eaf-e217-61be3ae9697c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x78f939260ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model LAB:**"
      ],
      "metadata": {
        "id": "kvODWjVrxmRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import PIL\n",
        "PIL.Image.MAX_IMAGE_PIXELS = 236958876\n",
        "\n",
        "n_size = 32\n",
        "size = n_size\n",
        "\n",
        "def lab_rgb_unnormalized(lab_image):\n",
        "    lab_array = np.array(lab_image/255)# Convert LAB image to numpy array\n",
        "    lab_array[..., 0] = lab_array[..., 0] * 100.0# Scale LAB values back to their original ranges\n",
        "    lab_array[..., 1] = (lab_array[..., 1] * 255.0) - 128\n",
        "    lab_array[..., 2] = (lab_array[..., 2] * 255.0) - 128\n",
        "    rgb_array_unnormalized = color.lab2rgb(lab_array)# Convert LAB to RGB colorspace\n",
        "    rgb_array_unnormalized = (rgb_array_unnormalized * 255).astype(np.uint8)# Scale RGB values back to the range [0, 255]\n",
        "    rgb_image_unnormalized = Image.fromarray(rgb_array_unnormalized, mode='RGB')# Convert RGB array back to image\n",
        "    return rgb_image_unnormalized\n",
        "\n",
        "def AB_rgb_unnormalized(lab_image, test_L):\n",
        "    lab_array = np.array(lab_image/255)# Convert LAB image to numpy array\n",
        "    lab_array[..., 0] = test_L #replacing L from the original input\n",
        "    lab_array[..., 1] = (lab_array[..., 1] * 255.0) - 128\n",
        "    lab_array[..., 2] = (lab_array[..., 2] * 255.0) - 128\n",
        "    rgb_array_unnormalized = color.lab2rgb(lab_array)# Convert LAB to RGB colorspace\n",
        "    rgb_array_unnormalized = (rgb_array_unnormalized * 255).astype(np.uint8)# Scale RGB values back to the range [0, 255]\n",
        "    rgb_image_unnormalized = Image.fromarray(rgb_array_unnormalized, mode='RGB')# Convert RGB array back to image\n",
        "    return rgb_image_unnormalized\n",
        "\n",
        "def crop_(im):\n",
        "    width, height = im.size\n",
        "    data = []\n",
        "    for j in range(0,int(height/n_size)):\n",
        "        for i in range(0,int(width/n_size)):\n",
        "            im1 = im.crop((0 + (n_size*i), 0 + (n_size*j), n_size + (n_size*i), n_size + (n_size*j)))\n",
        "            im1 = np.array(im1)\n",
        "            im1 = im1.astype(np.float32)\n",
        "            im1 = im1/255\n",
        "            data.append(im1)\n",
        "    return data\n",
        "\n",
        "#----------------READING THE TEST IMAGE--------------------#\n",
        "test = Image.open(file_path+ \"Testing/\" + filename).convert('RGB')\n",
        "test_L = color.rgb2lab(np.array(test))\n",
        "test_L = test_L[..., 0]\n",
        "test = rgb_lab_normalized(test)\n",
        "w_dirty, h_dirty = test.size\n",
        "#----------------------------------------------------------#\n",
        "\n",
        "autoencoder = keras.models.load_model(file_path + 'Model/unet_'+str(n_size)+'_lab')\n",
        "\n",
        "xx = int(w_dirty/n_size)\n",
        "final=[]\n",
        "for portion in range(0,xx):\n",
        "    im1 = test.crop((n_size*portion, 0, (n_size*portion) + n_size, h_dirty))\n",
        "    w1, h1 = im1.size\n",
        "    w = int(w1/n_size)\n",
        "    h = int(h1/n_size)\n",
        "    neverbeforeseen = np.array(crop_(im1))\n",
        "    decoded_imgs = autoencoder.predict(neverbeforeseen)\n",
        "    col = np.vstack((decoded_imgs[0],decoded_imgs[1]))\n",
        "    for i in range(2,h):\n",
        "        col = np.vstack((col,decoded_imgs[i]))\n",
        "    y = col\n",
        "    y = (y * 255).astype('uint8')\n",
        "    if portion == 0:\n",
        "        final = y\n",
        "    if portion > 0:\n",
        "        final = np.hstack((final,y))\n",
        "\n",
        "#----------------TEST ON FULL LAB--------------------#\n",
        "final_LAB = lab_rgb_unnormalized(final)\n",
        "final_LAB = np.squeeze(final_LAB)\n",
        "reconstructed_LAB = Image.fromarray(final_LAB)\n",
        "reconstructed_LAB.save(file_path + \"Testing/\"+\"Method_3_\"+filename)\n",
        "plt.figure(), plt.imshow(reconstructed_LAB)\n",
        "\n",
        "#----------------TEST ON L from input and AB from model--------------------#\n",
        "final_L_AB = AB_rgb_unnormalized(final, test_L)\n",
        "final_L_AB = np.squeeze(final_L_AB)\n",
        "reconstructed_L_AB = Image.fromarray(final_L_AB)\n",
        "reconstructed_L_AB.save(file_path + \"Testing/\"+\"Method_4_\"+filename)\n",
        "plt.figure(), plt.imshow(reconstructed_L_AB)"
      ],
      "metadata": {
        "id": "l2WOweoWxWeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model AB**"
      ],
      "metadata": {
        "id": "2ij1l4JRyQ3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import PIL\n",
        "PIL.Image.MAX_IMAGE_PIXELS = 236958876\n",
        "\n",
        "n_size = 32\n",
        "size = n_size\n",
        "\n",
        "def rgb_lab_normalized(im):\n",
        "    rgb_array = np.array(im) # Convert to numpy array\n",
        "    rgb_array_normalized = rgb_array / 255.0 # Normalize RGB values from 0 to 1\n",
        "    lab_array_normalized = color.rgb2lab(rgb_array_normalized) # Convert RGB to LAB colorspace\n",
        "    lab_array_normalized[..., 0] = (lab_array_normalized[..., 0]) / 100.0 # Scale LAB values to range [0, 1]\n",
        "    lab_array_normalized[..., 1] = (lab_array_normalized[..., 1] + 128) / 255.0\n",
        "    lab_array_normalized[..., 2] = (lab_array_normalized[..., 2] + 128) / 255.0\n",
        "    lab_image_normalized = Image.fromarray((lab_array_normalized * 255).astype(np.uint8), mode='LAB')# Convert LAB array back to image\n",
        "    return lab_image_normalized\n",
        "\n",
        "def AB_rgb_unnormalized(ab_image, test_L):\n",
        "    ab_array = np.array(ab_image)/255# Convert LAB image to numpy array\n",
        "    ab_array[..., 0] = (ab_array[..., 0] * 255.0) - 128\n",
        "    ab_array[..., 1] = (ab_array[..., 1] * 255.0) - 128\n",
        "    LAB_array = np.dstack((test_L, ab_array[:,:,0], ab_array[:,:,1]))\n",
        "    rgb_array_unnormalized = color.lab2rgb(LAB_array)# Convert LAB to RGB colorspace\n",
        "    rgb_array_unnormalized = (rgb_array_unnormalized * 255).astype(np.uint8)# Scale RGB values back to the range [0, 255]\n",
        "    rgb_image_unnormalized = Image.fromarray(rgb_array_unnormalized, mode='RGB')# Convert RGB array back to image\n",
        "    return rgb_image_unnormalized\n",
        "\n",
        "def crop_(im):\n",
        "    width, height = im.size\n",
        "    data = []\n",
        "    for j in range(0,int(height/n_size)):\n",
        "        for i in range(0,int(width/n_size)):\n",
        "            im1 = im.crop((0 + (n_size*i), 0 + (n_size*j), n_size + (n_size*i), n_size + (n_size*j)))\n",
        "            im1 = np.array(im1)\n",
        "            im1 = im1.astype(np.float32)\n",
        "            data.append(im1)\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "#----------------READING THE TEST IMAGE--------------------#\n",
        "test = Image.open(file_path+ \"Testing/\" + filename).convert('RGB')\n",
        "test_L = color.rgb2lab(np.array(test))\n",
        "test_L = np.array(test_L[..., 0]).astype('uint8')\n",
        "test = rgb_lab_normalized(test)\n",
        "#test = test[:,:,1:3]\n",
        "#test = np.array(test).astype(np.float32)/255.0\n",
        "w_dirty, h_dirty = test.size\n",
        "#----------------------------------------------------------#\n",
        "\n",
        "autoencoder = keras.models.load_model(file_path + 'Model/unet_'+str(n_size)+'_ab')\n",
        "\n",
        "xx = int(w_dirty/n_size)\n",
        "final=[]\n",
        "for portion in range(0,xx):\n",
        "    im1 = test.crop((n_size*portion, 0, (n_size*portion) + n_size, h_dirty))\n",
        "    w1, h1 = im1.size\n",
        "    w = int(w1/n_size)\n",
        "    h = int(h1/n_size)\n",
        "    neverbeforeseen = np.array(crop_(im1))\n",
        "    neverbeforeseen = neverbeforeseen[:,:,:,1:3]\n",
        "    neverbeforeseen = np.array(neverbeforeseen).astype(np.float32)/255.0\n",
        "    decoded_imgs = autoencoder.predict(neverbeforeseen)\n",
        "    col = np.vstack((decoded_imgs[0],decoded_imgs[1]))\n",
        "    for i in range(2,h):\n",
        "        col = np.vstack((col,decoded_imgs[i]))\n",
        "    y = col\n",
        "    y = (y * 255).astype('uint8')\n",
        "    if portion == 0:\n",
        "        final = y\n",
        "    if portion > 0:\n",
        "        final = np.hstack((final,y))\n",
        "\n",
        "#----------------TEST ON L from input and AB from model--------------------#\n",
        "final_L_AB = AB_rgb_unnormalized(final, test_L)\n",
        "final_L_AB = np.squeeze(final_L_AB)\n",
        "reconstructed_L_AB = Image.fromarray(final_L_AB)\n",
        "reconstructed_L_AB.save(file_path + \"Testing/\"+\"Model_5_\"+filename)\n",
        "plt.figure(), plt.imshow(reconstructed_L_AB)"
      ],
      "metadata": {
        "id": "jrXxXGj5yFs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model AB plus Model L**"
      ],
      "metadata": {
        "id": "EzOXFu1uyjLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import PIL\n",
        "PIL.Image.MAX_IMAGE_PIXELS = 236958876\n",
        "\n",
        "n_size = 32\n",
        "size = 32\n",
        "\n",
        "def rgb_lab_normalized(im):\n",
        "    rgb_array = np.array(im) # Convert to numpy array\n",
        "    rgb_array_normalized = rgb_array / 255.0 # Normalize RGB values from 0 to 1\n",
        "    lab_array_normalized = color.rgb2lab(rgb_array_normalized) # Convert RGB to LAB colorspace\n",
        "    lab_array_normalized[..., 0] = (lab_array_normalized[..., 0]) / 100.0 # Scale LAB values to range [0, 1]\n",
        "    lab_array_normalized[..., 1] = (lab_array_normalized[..., 1] + 128) / 255.0\n",
        "    lab_array_normalized[..., 2] = (lab_array_normalized[..., 2] + 128) / 255.0\n",
        "    lab_image_normalized = Image.fromarray((lab_array_normalized * 255).astype(np.uint8), mode='LAB')# Convert LAB array back to image\n",
        "    return lab_image_normalized\n",
        "\n",
        "def L_AB_rgb_unnormalized(ab_image, final_L):\n",
        "    ab_image = ab_image/255.0\n",
        "    final_L = final_L/255.0\n",
        "    final_L[..., 0] = final_L[..., 0]*100.0\n",
        "    ab_image[..., 0] = (ab_image[..., 0] * 255.0) - 128\n",
        "    ab_image[..., 1] = (ab_image[..., 1] * 255.0) - 128\n",
        "    LAB_array = np.dstack((final_L, ab_image[:,:,0], ab_image[:,:,1]))\n",
        "    rgb_array_unnormalized = color.lab2rgb(LAB_array)# Convert LAB to RGB colorspace\n",
        "    rgb_array_unnormalized = (rgb_array_unnormalized * 255).astype(np.uint8)# Scale RGB values back to the range [0, 255]\n",
        "    rgb_image_unnormalized = Image.fromarray(rgb_array_unnormalized, mode='RGB')# Convert RGB array back to image\n",
        "    return rgb_image_unnormalized\n",
        "\n",
        "def crop_(im):\n",
        "    width, height = im.size\n",
        "    data = []\n",
        "    for j in range(0,int(height/n_size)):\n",
        "        for i in range(0,int(width/n_size)):\n",
        "            im1 = im.crop((0 + (n_size*i), 0 + (n_size*j), n_size + (n_size*i), n_size + (n_size*j)))\n",
        "            im1 = np.array(im1)\n",
        "            im1 = im1.astype(np.float32)\n",
        "            data.append(im1)\n",
        "    return data\n",
        "\n",
        "\n",
        "#----------------READING THE TEST IMAGE--------------------#\n",
        "test = Image.open(file_path+ \"Testing/\" + filename).convert('RGB')\n",
        "test = rgb_lab_normalized(test)\n",
        "w_dirty, h_dirty = test.size\n",
        "#----------------------------------------------------------#\n",
        "\n",
        "#----------------GETTING AB--------------------#\n",
        "autoencoder = keras.models.load_model(file_path + 'Model/unet_'+str(n_size)+'_ab')\n",
        "\n",
        "xx = int(w_dirty/n_size)\n",
        "final=[]\n",
        "for portion in range(0,xx):\n",
        "    im1 = test.crop((n_size*portion, 0, (n_size*portion) + n_size, h_dirty))\n",
        "    w1, h1 = im1.size\n",
        "    w = int(w1/n_size)\n",
        "    h = int(h1/n_size)\n",
        "    neverbeforeseen = np.array(crop_(im1))\n",
        "    neverbeforeseen = neverbeforeseen[:,:,:,1:3]\n",
        "    neverbeforeseen = np.array(neverbeforeseen).astype(np.float32)/255.0\n",
        "    decoded_imgs = autoencoder.predict(neverbeforeseen)\n",
        "    col = np.vstack((decoded_imgs[0],decoded_imgs[1]))\n",
        "    for i in range(2,h):\n",
        "        col = np.vstack((col,decoded_imgs[i]))\n",
        "    y = col\n",
        "    y = (y * 255).astype('uint8')\n",
        "    if portion == 0:\n",
        "        final = y\n",
        "    if portion > 0:\n",
        "        final = np.hstack((final,y))\n",
        "\n",
        "#----------------GETTING L--------------------#\n",
        "autoencoder = keras.models.load_model(file_path + 'Model/unet_'+str(n_size)+'_L')\n",
        "\n",
        "final_L=[]\n",
        "for portion in range(0,xx):\n",
        "    im1 = test.crop((n_size*portion, 0, (n_size*portion) + n_size, h_dirty))\n",
        "    w1, h1 = im1.size\n",
        "    w = int(w1/n_size)\n",
        "    h = int(h1/n_size)\n",
        "    neverbeforeseen = np.array(crop_(im1))\n",
        "    neverbeforeseen = neverbeforeseen[:,:,:,0:1]\n",
        "    neverbeforeseen = np.array(neverbeforeseen).astype(np.float32)/255.0\n",
        "    decoded_imgs = autoencoder.predict(neverbeforeseen)\n",
        "    col = np.vstack((decoded_imgs[0],decoded_imgs[1]))\n",
        "    for i in range(2,h):\n",
        "        col = np.vstack((col,decoded_imgs[i]))\n",
        "    y = col\n",
        "    y = (y * 255).astype('uint8')\n",
        "    if portion == 0:\n",
        "        final_L = y\n",
        "    if portion > 0:\n",
        "        final_L = np.hstack((final_L,y))\n",
        "\n",
        "#----------------TEST ON L from model and AB from model--------------------#\n",
        "final_L_AB = L_AB_rgb_unnormalized(final, final_L)\n",
        "final_L_AB = np.squeeze(final_L_AB)\n",
        "reconstructed_L_AB = Image.fromarray(final_L_AB)\n",
        "reconstructed_L_AB.save(file_path + \"Testing/\"+\"Method_6_\"+filename)\n",
        "plt.figure(), plt.imshow(reconstructed_L_AB)"
      ],
      "metadata": {
        "id": "LTH18YqyypPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## COMPUTE SSIM SCORES"
      ],
      "metadata": {
        "id": "qo3xeQtXwVif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Function to open image and convert to numpy array\n",
        "def load_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')  # Ensure image is in RGB mode\n",
        "    return np.array(image)\n",
        "\n",
        "image_path1 = file_path + 'Testing/OUTPUT_[05] Comprimise-d.png'\n",
        "image_path2 = file_path + \"Testing/\"+\"Method_3_\"+str(size)+\"LAB_\"+filename\n",
        "\n",
        "# Load images\n",
        "image1 = load_image(image_path1)\n",
        "image2 = load_image(image_path2)\n",
        "\n",
        "# Ensure the images have the same dimensions\n",
        "if image1.shape != image2.shape:\n",
        "    raise ValueError(\"Input images must have the same dimensions.\")\n",
        "\n",
        "# Compute SSIM for each channel and average the results\n",
        "ssim_index_r = ssim(image1[:, :, 0], image2[:, :, 0], data_range=image1[:, :, 0].max() - image1[:, :, 0].min())\n",
        "ssim_index_g = ssim(image1[:, :, 1], image2[:, :, 1], data_range=image1[:, :, 1].max() - image1[:, :, 1].min())\n",
        "ssim_index_b = ssim(image1[:, :, 2], image2[:, :, 2], data_range=image1[:, :, 2].max() - image1[:, :, 2].min())\n",
        "\n",
        "ssim_index_rgb = (ssim_index_r + ssim_index_g + ssim_index_b) / 3\n",
        "\n",
        "print(f\"SSIM for R channel: {ssim_index_r}\")\n",
        "print(f\"SSIM for G channel: {ssim_index_g}\")\n",
        "print(f\"SSIM for B channel: {ssim_index_b}\")\n",
        "print(f\"Average SSIM for RGB image(Method3): {ssim_index_rgb}\")\n"
      ],
      "metadata": {
        "id": "MHIfhhpLHwNf",
        "outputId": "627c1f49-a23a-4e21-e02f-23c909e3a196",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SSIM for R channel: 0.509358346147561\n",
            "SSIM for G channel: 0.5081811788128479\n",
            "SSIM for B channel: 0.4024215496836909\n",
            "Average SSIM for RGB image(Method3): 0.4733203582146999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Function to open image and convert to numpy array\n",
        "def load_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')  # Ensure image is in RGB mode\n",
        "    return np.array(image)\n",
        "\n",
        "image_path1 = file_path + 'Testing/OUTPUT_[05] Comprimise-d.png'\n",
        "image_path2 = file_path + \"Testing/\"+\"Method_4_\"+str(size)+\"L_AB_\"+filename\n",
        "\n",
        "# Load images\n",
        "image1 = load_image(image_path1)\n",
        "image2 = load_image(image_path2)\n",
        "\n",
        "# Ensure the images have the same dimensions\n",
        "if image1.shape != image2.shape:\n",
        "    raise ValueError(\"Input images must have the same dimensions.\")\n",
        "\n",
        "# Compute SSIM for each channel and average the results\n",
        "ssim_index_r = ssim(image1[:, :, 0], image2[:, :, 0], data_range=image1[:, :, 0].max() - image1[:, :, 0].min())\n",
        "ssim_index_g = ssim(image1[:, :, 1], image2[:, :, 1], data_range=image1[:, :, 1].max() - image1[:, :, 1].min())\n",
        "ssim_index_b = ssim(image1[:, :, 2], image2[:, :, 2], data_range=image1[:, :, 2].max() - image1[:, :, 2].min())\n",
        "\n",
        "ssim_index_rgb = (ssim_index_r + ssim_index_g + ssim_index_b) / 3\n",
        "\n",
        "print(f\"SSIM for R channel: {ssim_index_r}\")\n",
        "print(f\"SSIM for G channel: {ssim_index_g}\")\n",
        "print(f\"SSIM for B channel: {ssim_index_b}\")\n",
        "print(f\"Average SSIM for RGB image(Method4): {ssim_index_rgb}\")\n"
      ],
      "metadata": {
        "id": "K_XXHvyDNokf",
        "outputId": "cd917983-a029-457c-ba09-72d2993273bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SSIM for R channel: 0.5487580309946481\n",
            "SSIM for G channel: 0.5692294383749303\n",
            "SSIM for B channel: 0.4253035732161732\n",
            "Average SSIM for RGB image(Method4): 0.514430347528584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "def compute_average_ssim(image1_path, image2_path):\n",
        "    # Open the images using Pillow\n",
        "    image1 = Image.open(image1_path).convert('RGB')\n",
        "    image2 = Image.open(image2_path).convert('RGB')\n",
        "\n",
        "    # Convert images from RGB to LAB color space using Pillow\n",
        "    lab_image1 = image1.convert('LAB')\n",
        "    lab_image2 = image2.convert('LAB')\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    lab_image1 = np.array(lab_image1)\n",
        "    lab_image2 = np.array(lab_image2)\n",
        "\n",
        "    # Extract the A and B channels\n",
        "    a_channel1, b_channel1 = lab_image1[:, :, 1], lab_image1[:, :, 2]\n",
        "    a_channel2, b_channel2 = lab_image2[:, :, 1], lab_image2[:, :, 2]\n",
        "\n",
        "    # Compute SSIM for the A channel\n",
        "    ssim_a = ssim(a_channel1, a_channel2)\n",
        "\n",
        "    # Compute SSIM for the B channel\n",
        "    ssim_b = ssim(b_channel1, b_channel2)\n",
        "\n",
        "    # Average the SSIM values\n",
        "    average_ssim = (ssim_a + ssim_b) / 2\n",
        "\n",
        "    return average_ssim\n",
        "\n",
        "# Paths to the images\n",
        "image1_path = file_path + 'Testing/OUTPUT_[05] Comprimise-d.png'\n",
        "image2_path = image_path2 = file_path + \"Testing/\"+\"Method_3_\"+str(size)+\"LAB_\"+filename\n",
        "\n",
        "# Compute the average SSIM\n",
        "average_ssim_value = compute_average_ssim(image1_path, image2_path)\n",
        "print(f\"Average SSIM (A and B channels (Method3)): {average_ssim_value}\")\n"
      ],
      "metadata": {
        "id": "FK867a9sNxwM",
        "outputId": "be49afbb-ce9c-40c9-c7e1-7a32b21e2081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average SSIM (A and B channels (Method3)): 0.4829091381886401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "def compute_average_ssim(image1_path, image2_path):\n",
        "    # Open the images using Pillow\n",
        "    image1 = Image.open(image1_path).convert('RGB')\n",
        "    image2 = Image.open(image2_path).convert('RGB')\n",
        "\n",
        "    # Convert images from RGB to LAB color space using Pillow\n",
        "    lab_image1 = image1.convert('LAB')\n",
        "    lab_image2 = image2.convert('LAB')\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    lab_image1 = np.array(lab_image1)\n",
        "    lab_image2 = np.array(lab_image2)\n",
        "\n",
        "    # Extract the A and B channels\n",
        "    a_channel1, b_channel1 = lab_image1[:, :, 1], lab_image1[:, :, 2]\n",
        "    a_channel2, b_channel2 = lab_image2[:, :, 1], lab_image2[:, :, 2]\n",
        "\n",
        "    # Compute SSIM for the A channel\n",
        "    ssim_a = ssim(a_channel1, a_channel2)\n",
        "\n",
        "    # Compute SSIM for the B channel\n",
        "    ssim_b = ssim(b_channel1, b_channel2)\n",
        "\n",
        "    # Average the SSIM values\n",
        "    average_ssim = (ssim_a + ssim_b) / 2\n",
        "\n",
        "    return average_ssim\n",
        "\n",
        "# Paths to the images\n",
        "image1_path = file_path + 'Testing/OUTPUT_[05] Comprimise-d.png'\n",
        "image2_path = image_path2 = file_path + \"Testing/\"+\"Method_4_\"+str(size)+\"L_AB_\"+filename\n",
        "\n",
        "# Compute the average SSIM\n",
        "average_ssim_value = compute_average_ssim(image1_path, image2_path)\n",
        "print(f\"Average SSIM (A and B channels (Method4)): {average_ssim_value}\")\n"
      ],
      "metadata": {
        "id": "HJJHBbh3SHZO",
        "outputId": "968b80df-3f0f-4714-83ad-270f209f7aad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average SSIM (A and B channels (Method4)): 0.4836187382989704\n"
          ]
        }
      ]
    }
  ]
}