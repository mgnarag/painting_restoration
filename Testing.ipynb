{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgnarag/painting_restoration/blob/main/Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXM5CNP5BaYU",
        "outputId": "f38082cb-0450-4dda-b018-9af6a5f049a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/My\\ Drive\n",
        "file_path = \"/content/drive/MyDrive/Baumgartner screenshots/\""
      ],
      "metadata": {
        "id": "xiAgOwvmBcjr",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3f8f72d-8fe1-4a04-dd20-507a19a9af0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'107.1 syllabus 1SAY1920 FINAL.gdoc'\n",
            "'1C-01 Narag et al (1).pdf'\n",
            "'1C-01 Narag et al.pdf'\n",
            "'1FA971504AC646559D05A8ED6341AFB3[1025340].png'\n",
            "'1H-04 Narag et al.pdf'\n",
            " 20220802_182749.heic\n",
            " 20220802_182831.heic\n",
            " 20220802_183259.heic\n",
            " 20220803_125819.heic\n",
            " 20220803_125842.heic\n",
            " 20220803_144229.heic\n",
            " 20220803_144422.heic\n",
            " 20220803_160724.heic\n",
            " 20220803_160751.heic\n",
            " 20220803_165240.heic\n",
            " 20220803_165318.heic\n",
            " 20220803_174701.heic\n",
            " 20220803_174706.heic\n",
            " 20220804_175217.heic\n",
            " 20220804_175443.heic\n",
            " 20220804_175616.heic\n",
            " 20220804_181917.heic\n",
            " 20220804_182007.heic\n",
            " 20220804_182117.heic\n",
            " 2S22-23_LE3-Regular-Set-A-FINAL-KEY.pdf\n",
            "'3 classes (polarized)CM_alexnet.png'\n",
            "'3 classes (polarized)CM_vgg.png'\n",
            "'A4_Physics 71 TWHFU-3_gradesheet (1).pdf'\n",
            "'A4_Physics 71 TWHFU-3_officialgrades (1).pdf'\n",
            "'A4_Physics 71 TWHFU-3_officialgrades.gdoc'\n",
            "'Abstract - NARAG, Mark Jeremy.pdf'\n",
            "'Annex 1 (copy of Journal).pdf'\n",
            "'Annex 2 (Proof of employments).pdf'\n",
            "'App Physics 181 THY-FX-2_studentcontactlist.xlsx'\n",
            " Architectural_designs\n",
            "'Arki abstract.pdf'\n",
            "'Arki full paper.pdf'\n",
            "'[ART] Example of Objectives - Activities - Exp Output OPTIKAL WBS version 2.gsheet'\n",
            " autoencoder_fine_tuned_6\n",
            "'autoencoder_fine_tuned_6 (1)'\n",
            " autoencoder_fine_tuned_6_b\n",
            "'Baumgartner screenshots'\n",
            "'Binarizing architectural drawings'\n",
            " classification_report_nonTL.xlsx\n",
            " classification_report.xlsx\n",
            " Classroom\n",
            "'CLEAN32_AB_INPUT_[09] Preserve and Protect.png'\n",
            "'CLEAN32_AB_TEST_INPUT_[04] Coming into Bloom_V1.png'\n",
            "'CLEAN32LAB_Copy of [05] Comprimise-d - Before.png'\n",
            "'CLEAN_TEST_INPUT_[04] Coming into Bloom.png'\n",
            "'Colab Notebooks'\n",
            "'Color Difference Specification 2016.pptx'\n",
            " confusion_matrix_nonTL.png\n",
            " confusion_matrix_nonTL.xlsx\n",
            " CS284\n",
            " CS_NIP_201819_S2_BS_AppliedPhysics_Narag_Mark_Jeremy.pdf\n",
            " D54dUVpU8AIZzoD.jpeg\n",
            " Data.tex\n",
            "'Dormitory Stay Request MNarag.docx.pdf'\n",
            "'[DRAFT-ART] UP Intelligent Systems Center Research Grant Application - Preview.docx'\n",
            " DrzPc0sUwAAyQHi.jpeg\n",
            " DvO96koV4AAD6PP.jpeg\n",
            "'DvO976tVAAEQ9ym (1).jpeg'\n",
            " DvO976tVAAEQ9ym.jpeg\n",
            "'Employment Survey.gdoc'\n",
            " Fast-Dreambooth\n",
            "'FBC-2_Banez (1).pdf'\n",
            " FBC-2_Banez.pdf\n",
            " FdUaD2nUcAAki1b.jpeg\n",
            "'Figure 1.png'\n",
            "'Figure 2.png'\n",
            "'fingerprint (1).pb'\n",
            "'fingerprint (2).pb'\n",
            "'fingerprint (3).pb'\n",
            "'fingerprint (4).pb'\n",
            "'fingerprint (5).pb'\n",
            " fingerprint.pb\n",
            "'Form5a and Grades.zip'\n",
            " Fringes.zip\n",
            " FSR_120201_NARAG_MARK_JEREMY_GACIAS_NIP.pdf\n",
            " FSR_120202_NARAG_MARK_JEREMY_GACIAS_NIP.pdf\n",
            " FSR_120212_NARAG_MARK_JEREMY_GACIAS_NIP.pdf\n",
            " FSR_120221_NARAG_MARK_JEREMY_GACIAS_NIP.pdf\n",
            "'Geology (Ate Grass)'\n",
            "'Geology (Ate Grass) (1)'\n",
            "'Getting started.pdf'\n",
            " IMG_4258.HEIC\n",
            " IMG_4259.HEIC\n",
            " IMG_4260.HEIC\n",
            " IMG_4261.HEIC\n",
            " IMG_4262.HEIC\n",
            " IMG_4263.HEIC\n",
            " IMG_4288.HEIC\n",
            " IMG_5634.JPG\n",
            " IMG_6572.jpeg\n",
            " IMG_6578.jpeg\n",
            "'IMG_6587 (1).jpeg'\n",
            " IMG_6587.jpeg\n",
            " IPA-Form4.1-2021Rev072021-1.pdf\n",
            " IPA-Form4.2-2021Rev072021.docx\n",
            " IPA-Form4.3-2021Rev072021.pdf\n",
            "'item sample.tex'\n",
            "'item template.tex'\n",
            "'Jas Jem utang.gsheet'\n",
            " Jem_face\n",
            "'JFR Reduced Fees for 1st Sem AY 20-21.zip'\n",
            "'Lecture 22 - Torque.pptx'\n",
            "'Lecture 23 - Dynamics of Rotation.pptx'\n",
            "'Lecture 24 - Angular Momentum.pptx'\n",
            "'Lecture 25 - Equilibrium and Center of Gravity.pptx'\n",
            "'Lecture 26 - Density and Pressure in a Fluid.pptx'\n",
            "'Lecture 27 - Buoyancy.pptx'\n",
            "'LRM_20220804_195432 (1).dng'\n",
            " LRM_20220804_195432.dng\n",
            " LRM_20220804_195500.dng\n",
            " LRM_20220804_195546.dng\n",
            " LRM_20220805_113837.dng\n",
            " LRM_20220805_142837.dng\n",
            " LRM_20220805_143054.dng\n",
            " LRM_20220805_143817.dng\n",
            "'MALIPOL_CHAE ANN.pdf'\n",
            " Metric_100dpi.csv\n",
            " Metric_500.csv\n",
            "'NARAG_MARKJEREMY (1).BC.pdf'\n",
            " NARAG_MARKJEREMY.BC.pdf\n",
            " NARAG_MARKJEREMY.CC.png\n",
            " NARAG_MARKJEREMY.dcog.pdf\n",
            " NARAG_MARKJEREMY.DC.pdf\n",
            " NARAG_MARKJEREMY.FL.pdf\n",
            " NARAG_MARKJEREMY.Form1.1.pdf\n",
            " NARAG_MARKJEREMY.POS.pdf\n",
            " NARAG_MARKJEREMY.SD.pdf\n",
            " NARAG_MARKJEREMY.TCGTOR.pdf\n",
            "'[NARAG] Physics 242 Final Report.pdf'\n",
            "'[NARAG] Physics 242 PS 1.pdf'\n",
            "'[NARAG] Physics 242 PS 2.pdf'\n",
            "'Narag SPP Cert.pdf'\n",
            " NARAG_Travel-Report-Form-2019.pdf\n",
            "'NIP COVID-19 Case Report Form.gform'\n",
            "'NIP COVID-19 Case Report Form (Responses).gsheet'\n",
            "'NIP COVID19 Report.gsheet'\n",
            "'NIP Year End Party 2022'\n",
            " NRAG_MARKJEREMY.OTRTCG.pdf\n",
            "'Optics in Art and Art Analysis (1).pptx'\n",
            "'Optics in Art and Art Analysis.pptx'\n",
            "'OUR CErtificate.gdoc'\n",
            "'OUR CErtificate.pdf'\n",
            "'output v1_100dpi.png'\n",
            "'output v2_100dpi.png'\n",
            "'output v3_100dpi.png'\n",
            "'output v3_500.png'\n",
            "'output v4_100dpi.png'\n",
            "'output v5_100dpi.png'\n",
            "'output v6_100dpi.png'\n",
            "'OVCRD IPA Reference Slip (2021-0929-1691-5873).pdf'\n",
            "'PA-08 Narag et al.pdf'\n",
            " PA-08.pdf\n",
            "'Parallel Presentation.gslides'\n",
            "'PEER EVALUTION - Physics 72.1 HBC-1 .gform'\n",
            "'PEER EVALUTION - Physics 72.1 TDE-1 .gform'\n",
            "'PEER EVALUTION - Physics 72.1 WDE-1 .gform'\n",
            "'PhD Candidacy Slides.pdf'\n",
            "'PhD Candidacy Slides.pptx'\n",
            "'Physics 107.1 Drive'\n",
            "'Physics 107.1 MBCD-2_studentcontactlist.xlsx'\n",
            " Physics305_plasma\n",
            "'Physics 71.1 WIJ FIJ and 72.1 TBC.gsheet'\n",
            " Physics_71_Syllabus.zip\n",
            "'Physics_71_Syllabus.zip (Unzipped Files)'\n",
            "'[Physics 71 V-2] Attendance.gsheet'\n",
            "'Physics 72.1 2nd Sem AY 2019-2020.gsheet'\n",
            "'Rene Jem utang.gsheet'\n",
            "'Research files'\n",
            "'Sablay picture.jpeg'\n",
            "'saved_model (1).pb'\n",
            "'saved_model (2).pb'\n",
            "'saved_model (3).pb'\n",
            "'saved_model (4).pb'\n",
            "'saved_model (5).pb'\n",
            " saved_model.pb\n",
            "'Screenshot 2023-02-12 at 12.13.51 (1).png'\n",
            "'Screenshot 2023-02-12 at 12.13.51.png'\n",
            "'Screenshot 2023-06-29 at 19.20.04.png'\n",
            "'Screenshot 2023-06-29 at 19.26.09.png'\n",
            " sd\n",
            " Smokers.mp4\n",
            "'SORRY SIR HUHU.gdoc'\n",
            "'SORRY SIR HUHU.pdf'\n",
            "'SPP-2023-1H-04 (1).pptx'\n",
            " SPP-2023-1H-04.pptx\n",
            " SPP_2023-Contributed-26.pdf\n",
            "'SPP-2023-PB-05  .pdf'\n",
            " SPP_Appearance-45.pdf\n",
            "'SPP Cert of Appearance NARAG (1).pdf'\n",
            "'SPP Cert of Appearance NARAG (2).pdf'\n",
            "'SPP Cert of Appearance NARAG.pdf'\n",
            "'Testing on DIV2K dataset.pdf'\n",
            "'[THY-FX] Physics 181 LE1 Submissions 2nd Sem AY 2020-21'\n",
            " Travel-Report-Form-2019.pdf\n",
            "'Undergraduate Research'\n",
            "'Untitled spreadsheet (1).gsheet'\n",
            "'Untitled spreadsheet.gsheet'\n",
            "'[Updated] Physics 71 THQ-FQ-1_studentcontactlist (1).xlsx'\n",
            "'[Updated] Physics 71 THQ-FQ-1_studentcontactlist.xlsx'\n",
            "'variables (1).data-00000-of-00001'\n",
            "'variables (2).data-00000-of-00001'\n",
            "'variables (3).data-00000-of-00001'\n",
            "'variables (4).data-00000-of-00001'\n",
            "'variables (5).data-00000-of-00001'\n",
            " variables.data-00000-of-00001\n",
            "'Waiver for more than 18 units [2nd sem AY 20-21].gdoc'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing packages"
      ],
      "metadata": {
        "id": "zEoJQzJ5bM8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image, ImageOps\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import zoom\n",
        "\n",
        "import cv2\n",
        "from skimage import color\n",
        "\n",
        "from tensorflow import keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import PIL\n",
        "PIL.Image.MAX_IMAGE_PIXELS = 236958876\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "FgE9bH4-MFlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining functions"
      ],
      "metadata": {
        "id": "ihq928NMbTBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def zoom_and_resize(img, zoom_factor):\n",
        "    height, width = img.shape[:2]\n",
        "    crop_top = int((height - height / zoom_factor) / 2)# Calculate the region to crop around the center\n",
        "    crop_bottom = int(height - crop_top)\n",
        "    crop_left = int((width - width / zoom_factor) / 2)\n",
        "    crop_right = int(width - crop_left)\n",
        "    cropped_image = img[crop_top:crop_bottom, crop_left:crop_right]    # Crop the image\n",
        "    resized_image = cv2.resize(cropped_image, (width, height))# Resize the zoomed image back to the original dimensions\n",
        "    return resized_image\n",
        "\n",
        "def crop(im):\n",
        "    width, height = im.size\n",
        "    data = []\n",
        "    step = int(size * 0.80)  # Adjust the step size for cropping\n",
        "    for j in range(0, height, step):\n",
        "        for i in range(0, width, step):\n",
        "            if i + size <= width and j + size <= height:\n",
        "                im1 = im.crop((i, j, i + size, j + size))\n",
        "                im1 = np.array(im1).astype(np.float32)\n",
        "                data.append(im1/255)\n",
        "                im1 = np.rot90(im1)\n",
        "                data.append(im1/255)\n",
        "                #im1 = np.rot90(im1)\n",
        "                #data.append(im1/255)\n",
        "                #im1 = np.rot90(im1)\n",
        "                #data.append(im1/255)\n",
        "                #for z in zoom_factor:\n",
        "                #    zoomed_img = zoom_and_resize(im1, z)\n",
        "                #    data.append(zoomed_img/255)\n",
        "    return data\n",
        "\n",
        "def rgb_lab_normalized(im):\n",
        "    rgb_array = np.array(im) # Convert to numpy array\n",
        "    rgb_array_normalized = rgb_array / 255.0 # Normalize RGB values from 0 to 1\n",
        "    lab_array_normalized = color.rgb2lab(rgb_array_normalized) # Convert RGB to LAB colorspace\n",
        "    lab_array_normalized[..., 0] = (lab_array_normalized[..., 0]) / 100.0 # Scale LAB values to range [0, 1]\n",
        "    lab_array_normalized[..., 1] = (lab_array_normalized[..., 1] + 128) / 255.0\n",
        "    lab_array_normalized[..., 2] = (lab_array_normalized[..., 2] + 128) / 255.0\n",
        "    lab_image_normalized = Image.fromarray((lab_array_normalized * 255).astype(np.uint8), mode='LAB')# Convert LAB array back to image\n",
        "    return lab_image_normalized"
      ],
      "metadata": {
        "id": "GRBwljTxNi-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model"
      ],
      "metadata": {
        "id": "3lnB29-_cVp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = str(\"INPUT_[05] Comprimise-d.png\")"
      ],
      "metadata": {
        "id": "_gpX2nMPx7JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model RGB:**"
      ],
      "metadata": {
        "id": "EWPFTVoVxePF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_size = 32\n",
        "size = 32\n",
        "\n",
        "def rgb_L_ab(rgb_image, test_L):\n",
        "    lab_array = color.rgb2lab(np.array(rgb_image))# Convert RGB to LAB colorspace\n",
        "    lab_array[..., 0] = test_L #Change L channel to input\n",
        "    rgb_array = color.lab2rgb(lab_array)# Convert back LAB to RGB colorspace\n",
        "    rgb_array = (rgb_array * 255).astype(np.uint8)# Scale RGB values back to the range [0, 255]\n",
        "    rgb_array = Image.fromarray(rgb_array, mode='RGB')# Convert RGB array back to image\n",
        "    return rgb_array\n",
        "\n",
        "def crop_(im):\n",
        "    width, height = im.size\n",
        "    data = []\n",
        "    for j in range(0,int(height/n_size)):\n",
        "        for i in range(0,int(width/n_size)):\n",
        "            im1 = im.crop((0 + (n_size*i), 0 + (n_size*j), n_size + (n_size*i), n_size + (n_size*j)))\n",
        "            im1 = np.array(im1)\n",
        "            im1 = im1.astype(np.float32)\n",
        "            im1 = im1/255\n",
        "            data.append(im1)\n",
        "    return data\n",
        "\n",
        "#----------------READING THE TEST IMAGE--------------------#\n",
        "filename = str(\"INPUT_[09] Preserve and Protect.png\")\n",
        "test = Image.open(file_path+ \"Testing/\" + filename).convert('RGB')\n",
        "test_L = color.rgb2lab(np.array(test))\n",
        "test_L = test_L[..., 0]\n",
        "w_dirty, h_dirty = test.size\n",
        "#----------------------------------------------------------#\n",
        "\n",
        "autoencoder = keras.models.load_model(file_path + 'Model/unet_'+str(n_size)+'_rgb')\n",
        "\n",
        "xx = int(w_dirty/n_size)\n",
        "final=[]\n",
        "\n",
        "for portion in range(0,xx):\n",
        "    im1 = test.crop((n_size*portion, 0, (n_size*portion) + n_size, h_dirty))\n",
        "    w1, h1 = im1.size\n",
        "    w = int(w1/n_size)\n",
        "    h = int(h1/n_size)\n",
        "    neverbeforeseen = np.array(crop_(im1))\n",
        "    decoded_imgs = autoencoder.predict(neverbeforeseen)\n",
        "    col = np.vstack((decoded_imgs[0],decoded_imgs[1]))\n",
        "    for i in range(2,h):\n",
        "        col = np.vstack((col,decoded_imgs[i]))\n",
        "    y = col\n",
        "    y = (y * 255).astype('uint8')\n",
        "    if portion == 0:\n",
        "        final = y\n",
        "    if portion > 0:\n",
        "        final = np.hstack((final,y))\n",
        "\n",
        "#----------------TEST ON FULL RGB--------------------#\n",
        "final_rgb = final\n",
        "final_rgb = np.squeeze(final_rgb)\n",
        "reconstructed_rgb = Image.fromarray(final_rgb)\n",
        "reconstructed_rgb.save(file_path + \"Testing/\"+\"Model_1_\"+filename)\n",
        "plt.figure(), plt.imshow(reconstructed_rgb)\n",
        "\n",
        "#----------------TEST ON L from input and AB from convert RGB2LAB of model--------------------#\n",
        "final_lab = rgb_L_ab(final, test_L)\n",
        "final_lab = np.squeeze(final_lab)\n",
        "reconstructed_lab = Image.fromarray(final_lab)\n",
        "reconstructed_lab.save(file_path + \"Testing/\"+\"Model_2_\"+filename)\n",
        "plt.figure(), plt.imshow(reconstructed_lab)"
      ],
      "metadata": {
        "id": "y3j1v9uGdbTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model LAB:**"
      ],
      "metadata": {
        "id": "kvODWjVrxmRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import PIL\n",
        "PIL.Image.MAX_IMAGE_PIXELS = 236958876\n",
        "\n",
        "n_size = 32\n",
        "size = n_size\n",
        "\n",
        "def lab_rgb_unnormalized(lab_image):\n",
        "    lab_array = np.array(lab_image/255)# Convert LAB image to numpy array\n",
        "    lab_array[..., 0] = lab_array[..., 0] * 100.0# Scale LAB values back to their original ranges\n",
        "    lab_array[..., 1] = (lab_array[..., 1] * 255.0) - 128\n",
        "    lab_array[..., 2] = (lab_array[..., 2] * 255.0) - 128\n",
        "    rgb_array_unnormalized = color.lab2rgb(lab_array)# Convert LAB to RGB colorspace\n",
        "    rgb_array_unnormalized = (rgb_array_unnormalized * 255).astype(np.uint8)# Scale RGB values back to the range [0, 255]\n",
        "    rgb_image_unnormalized = Image.fromarray(rgb_array_unnormalized, mode='RGB')# Convert RGB array back to image\n",
        "    return rgb_image_unnormalized\n",
        "\n",
        "def AB_rgb_unnormalized(lab_image, test_L):\n",
        "    lab_array = np.array(lab_image/255)# Convert LAB image to numpy array\n",
        "    lab_array[..., 0] = test_L #replacing L from the original input\n",
        "    lab_array[..., 1] = (lab_array[..., 1] * 255.0) - 128\n",
        "    lab_array[..., 2] = (lab_array[..., 2] * 255.0) - 128\n",
        "    rgb_array_unnormalized = color.lab2rgb(lab_array)# Convert LAB to RGB colorspace\n",
        "    rgb_array_unnormalized = (rgb_array_unnormalized * 255).astype(np.uint8)# Scale RGB values back to the range [0, 255]\n",
        "    rgb_image_unnormalized = Image.fromarray(rgb_array_unnormalized, mode='RGB')# Convert RGB array back to image\n",
        "    return rgb_image_unnormalized\n",
        "\n",
        "def crop_(im):\n",
        "    width, height = im.size\n",
        "    data = []\n",
        "    for j in range(0,int(height/n_size)):\n",
        "        for i in range(0,int(width/n_size)):\n",
        "            im1 = im.crop((0 + (n_size*i), 0 + (n_size*j), n_size + (n_size*i), n_size + (n_size*j)))\n",
        "            im1 = np.array(im1)\n",
        "            im1 = im1.astype(np.float32)\n",
        "            im1 = im1/255\n",
        "            data.append(im1)\n",
        "    return data\n",
        "\n",
        "#----------------READING THE TEST IMAGE--------------------#\n",
        "test = Image.open(file_path+ \"Testing/\" + filename).convert('RGB')\n",
        "test_L = color.rgb2lab(np.array(test))\n",
        "test_L = test_L[..., 0]\n",
        "test = rgb_lab_normalized(test)\n",
        "w_dirty, h_dirty = test.size\n",
        "#----------------------------------------------------------#\n",
        "\n",
        "autoencoder = keras.models.load_model(file_path + 'Model/unet_'+str(n_size)+'_lab')\n",
        "\n",
        "xx = int(w_dirty/n_size)\n",
        "final=[]\n",
        "for portion in range(0,xx):\n",
        "    im1 = test.crop((n_size*portion, 0, (n_size*portion) + n_size, h_dirty))\n",
        "    w1, h1 = im1.size\n",
        "    w = int(w1/n_size)\n",
        "    h = int(h1/n_size)\n",
        "    neverbeforeseen = np.array(crop_(im1))\n",
        "    decoded_imgs = autoencoder.predict(neverbeforeseen)\n",
        "    col = np.vstack((decoded_imgs[0],decoded_imgs[1]))\n",
        "    for i in range(2,h):\n",
        "        col = np.vstack((col,decoded_imgs[i]))\n",
        "    y = col\n",
        "    y = (y * 255).astype('uint8')\n",
        "    if portion == 0:\n",
        "        final = y\n",
        "    if portion > 0:\n",
        "        final = np.hstack((final,y))\n",
        "\n",
        "#----------------TEST ON FULL LAB--------------------#\n",
        "final_LAB = lab_rgb_unnormalized(final)\n",
        "final_LAB = np.squeeze(final_LAB)\n",
        "reconstructed_LAB = Image.fromarray(final_LAB)\n",
        "reconstructed_LAB.save(file_path + \"Testing/\"+\"Method_3_\"+filename)\n",
        "plt.figure(), plt.imshow(reconstructed_LAB)\n",
        "\n",
        "#----------------TEST ON L from input and AB from model--------------------#\n",
        "final_L_AB = AB_rgb_unnormalized(final, test_L)\n",
        "final_L_AB = np.squeeze(final_L_AB)\n",
        "reconstructed_L_AB = Image.fromarray(final_L_AB)\n",
        "reconstructed_L_AB.save(file_path + \"Testing/\"+\"Method_4_\"+filename)\n",
        "plt.figure(), plt.imshow(reconstructed_L_AB)"
      ],
      "metadata": {
        "id": "l2WOweoWxWeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model AB**"
      ],
      "metadata": {
        "id": "2ij1l4JRyQ3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import PIL\n",
        "PIL.Image.MAX_IMAGE_PIXELS = 236958876\n",
        "\n",
        "n_size = 32\n",
        "size = n_size\n",
        "\n",
        "def rgb_lab_normalized(im):\n",
        "    rgb_array = np.array(im) # Convert to numpy array\n",
        "    rgb_array_normalized = rgb_array / 255.0 # Normalize RGB values from 0 to 1\n",
        "    lab_array_normalized = color.rgb2lab(rgb_array_normalized) # Convert RGB to LAB colorspace\n",
        "    lab_array_normalized[..., 0] = (lab_array_normalized[..., 0]) / 100.0 # Scale LAB values to range [0, 1]\n",
        "    lab_array_normalized[..., 1] = (lab_array_normalized[..., 1] + 128) / 255.0\n",
        "    lab_array_normalized[..., 2] = (lab_array_normalized[..., 2] + 128) / 255.0\n",
        "    lab_image_normalized = Image.fromarray((lab_array_normalized * 255).astype(np.uint8), mode='LAB')# Convert LAB array back to image\n",
        "    return lab_image_normalized\n",
        "\n",
        "def AB_rgb_unnormalized(ab_image, test_L):\n",
        "    ab_array = np.array(ab_image)/255# Convert LAB image to numpy array\n",
        "    ab_array[..., 0] = (ab_array[..., 0] * 255.0) - 128\n",
        "    ab_array[..., 1] = (ab_array[..., 1] * 255.0) - 128\n",
        "    LAB_array = np.dstack((test_L, ab_array[:,:,0], ab_array[:,:,1]))\n",
        "    rgb_array_unnormalized = color.lab2rgb(LAB_array)# Convert LAB to RGB colorspace\n",
        "    rgb_array_unnormalized = (rgb_array_unnormalized * 255).astype(np.uint8)# Scale RGB values back to the range [0, 255]\n",
        "    rgb_image_unnormalized = Image.fromarray(rgb_array_unnormalized, mode='RGB')# Convert RGB array back to image\n",
        "    return rgb_image_unnormalized\n",
        "\n",
        "def crop_(im):\n",
        "    width, height = im.size\n",
        "    data = []\n",
        "    for j in range(0,int(height/n_size)):\n",
        "        for i in range(0,int(width/n_size)):\n",
        "            im1 = im.crop((0 + (n_size*i), 0 + (n_size*j), n_size + (n_size*i), n_size + (n_size*j)))\n",
        "            im1 = np.array(im1)\n",
        "            im1 = im1.astype(np.float32)\n",
        "            data.append(im1)\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "#----------------READING THE TEST IMAGE--------------------#\n",
        "test = Image.open(file_path+ \"Testing/\" + filename).convert('RGB')\n",
        "test_L = color.rgb2lab(np.array(test))\n",
        "test_L = np.array(test_L[..., 0]).astype('uint8')\n",
        "test = rgb_lab_normalized(test)\n",
        "#test = test[:,:,1:3]\n",
        "#test = np.array(test).astype(np.float32)/255.0\n",
        "w_dirty, h_dirty = test.size\n",
        "#----------------------------------------------------------#\n",
        "\n",
        "autoencoder = keras.models.load_model(file_path + 'Model/unet_'+str(n_size)+'_ab')\n",
        "\n",
        "xx = int(w_dirty/n_size)\n",
        "final=[]\n",
        "for portion in range(0,xx):\n",
        "    im1 = test.crop((n_size*portion, 0, (n_size*portion) + n_size, h_dirty))\n",
        "    w1, h1 = im1.size\n",
        "    w = int(w1/n_size)\n",
        "    h = int(h1/n_size)\n",
        "    neverbeforeseen = np.array(crop_(im1))\n",
        "    neverbeforeseen = neverbeforeseen[:,:,:,1:3]\n",
        "    neverbeforeseen = np.array(neverbeforeseen).astype(np.float32)/255.0\n",
        "    decoded_imgs = autoencoder.predict(neverbeforeseen)\n",
        "    col = np.vstack((decoded_imgs[0],decoded_imgs[1]))\n",
        "    for i in range(2,h):\n",
        "        col = np.vstack((col,decoded_imgs[i]))\n",
        "    y = col\n",
        "    y = (y * 255).astype('uint8')\n",
        "    if portion == 0:\n",
        "        final = y\n",
        "    if portion > 0:\n",
        "        final = np.hstack((final,y))\n",
        "\n",
        "#----------------TEST ON L from input and AB from model--------------------#\n",
        "final_L_AB = AB_rgb_unnormalized(final, test_L)\n",
        "final_L_AB = np.squeeze(final_L_AB)\n",
        "reconstructed_L_AB = Image.fromarray(final_L_AB)\n",
        "reconstructed_L_AB.save(file_path + \"Testing/\"+\"Model_5_\"+filename)\n",
        "plt.figure(), plt.imshow(reconstructed_L_AB)"
      ],
      "metadata": {
        "id": "jrXxXGj5yFs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model AB plus Model L**"
      ],
      "metadata": {
        "id": "EzOXFu1uyjLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "import PIL\n",
        "PIL.Image.MAX_IMAGE_PIXELS = 236958876\n",
        "\n",
        "n_size = 32\n",
        "size = 32\n",
        "\n",
        "def rgb_lab_normalized(im):\n",
        "    rgb_array = np.array(im) # Convert to numpy array\n",
        "    rgb_array_normalized = rgb_array / 255.0 # Normalize RGB values from 0 to 1\n",
        "    lab_array_normalized = color.rgb2lab(rgb_array_normalized) # Convert RGB to LAB colorspace\n",
        "    lab_array_normalized[..., 0] = (lab_array_normalized[..., 0]) / 100.0 # Scale LAB values to range [0, 1]\n",
        "    lab_array_normalized[..., 1] = (lab_array_normalized[..., 1] + 128) / 255.0\n",
        "    lab_array_normalized[..., 2] = (lab_array_normalized[..., 2] + 128) / 255.0\n",
        "    lab_image_normalized = Image.fromarray((lab_array_normalized * 255).astype(np.uint8), mode='LAB')# Convert LAB array back to image\n",
        "    return lab_image_normalized\n",
        "\n",
        "def L_AB_rgb_unnormalized(ab_image, final_L):\n",
        "    ab_image = ab_image/255.0\n",
        "    final_L = final_L/255.0\n",
        "    final_L[..., 0] = final_L[..., 0]*100.0\n",
        "    ab_image[..., 0] = (ab_image[..., 0] * 255.0) - 128\n",
        "    ab_image[..., 1] = (ab_image[..., 1] * 255.0) - 128\n",
        "    LAB_array = np.dstack((final_L, ab_image[:,:,0], ab_image[:,:,1]))\n",
        "    rgb_array_unnormalized = color.lab2rgb(LAB_array)# Convert LAB to RGB colorspace\n",
        "    rgb_array_unnormalized = (rgb_array_unnormalized * 255).astype(np.uint8)# Scale RGB values back to the range [0, 255]\n",
        "    rgb_image_unnormalized = Image.fromarray(rgb_array_unnormalized, mode='RGB')# Convert RGB array back to image\n",
        "    return rgb_image_unnormalized\n",
        "\n",
        "def crop_(im):\n",
        "    width, height = im.size\n",
        "    data = []\n",
        "    for j in range(0,int(height/n_size)):\n",
        "        for i in range(0,int(width/n_size)):\n",
        "            im1 = im.crop((0 + (n_size*i), 0 + (n_size*j), n_size + (n_size*i), n_size + (n_size*j)))\n",
        "            im1 = np.array(im1)\n",
        "            im1 = im1.astype(np.float32)\n",
        "            data.append(im1)\n",
        "    return data\n",
        "\n",
        "\n",
        "#----------------READING THE TEST IMAGE--------------------#\n",
        "test = Image.open(file_path+ \"Testing/\" + filename).convert('RGB')\n",
        "test = rgb_lab_normalized(test)\n",
        "w_dirty, h_dirty = test.size\n",
        "#----------------------------------------------------------#\n",
        "\n",
        "#----------------GETTING AB--------------------#\n",
        "autoencoder = keras.models.load_model(file_path + 'Model/unet_'+str(n_size)+'_ab')\n",
        "\n",
        "xx = int(w_dirty/n_size)\n",
        "final=[]\n",
        "for portion in range(0,xx):\n",
        "    im1 = test.crop((n_size*portion, 0, (n_size*portion) + n_size, h_dirty))\n",
        "    w1, h1 = im1.size\n",
        "    w = int(w1/n_size)\n",
        "    h = int(h1/n_size)\n",
        "    neverbeforeseen = np.array(crop_(im1))\n",
        "    neverbeforeseen = neverbeforeseen[:,:,:,1:3]\n",
        "    neverbeforeseen = np.array(neverbeforeseen).astype(np.float32)/255.0\n",
        "    decoded_imgs = autoencoder.predict(neverbeforeseen)\n",
        "    col = np.vstack((decoded_imgs[0],decoded_imgs[1]))\n",
        "    for i in range(2,h):\n",
        "        col = np.vstack((col,decoded_imgs[i]))\n",
        "    y = col\n",
        "    y = (y * 255).astype('uint8')\n",
        "    if portion == 0:\n",
        "        final = y\n",
        "    if portion > 0:\n",
        "        final = np.hstack((final,y))\n",
        "\n",
        "#----------------GETTING L--------------------#\n",
        "autoencoder = keras.models.load_model(file_path + 'Model/unet_'+str(n_size)+'_L')\n",
        "\n",
        "final_L=[]\n",
        "for portion in range(0,xx):\n",
        "    im1 = test.crop((n_size*portion, 0, (n_size*portion) + n_size, h_dirty))\n",
        "    w1, h1 = im1.size\n",
        "    w = int(w1/n_size)\n",
        "    h = int(h1/n_size)\n",
        "    neverbeforeseen = np.array(crop_(im1))\n",
        "    neverbeforeseen = neverbeforeseen[:,:,:,0:1]\n",
        "    neverbeforeseen = np.array(neverbeforeseen).astype(np.float32)/255.0\n",
        "    decoded_imgs = autoencoder.predict(neverbeforeseen)\n",
        "    col = np.vstack((decoded_imgs[0],decoded_imgs[1]))\n",
        "    for i in range(2,h):\n",
        "        col = np.vstack((col,decoded_imgs[i]))\n",
        "    y = col\n",
        "    y = (y * 255).astype('uint8')\n",
        "    if portion == 0:\n",
        "        final_L = y\n",
        "    if portion > 0:\n",
        "        final_L = np.hstack((final_L,y))\n",
        "\n",
        "#----------------TEST ON L from model and AB from model--------------------#\n",
        "final_L_AB = L_AB_rgb_unnormalized(final, final_L)\n",
        "final_L_AB = np.squeeze(final_L_AB)\n",
        "reconstructed_L_AB = Image.fromarray(final_L_AB)\n",
        "reconstructed_L_AB.save(file_path + \"Testing/\"+\"Method_6_\"+filename)\n",
        "plt.figure(), plt.imshow(reconstructed_L_AB)"
      ],
      "metadata": {
        "id": "LTH18YqyypPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## COMPUTE SSIM SCORES"
      ],
      "metadata": {
        "id": "qo3xeQtXwVif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Function to open image and convert to numpy array\n",
        "def load_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')  # Ensure image is in RGB mode\n",
        "    return np.array(image)\n",
        "\n",
        "image_path1 = file_path + 'Testing/OUTPUT_[05] Comprimise-d.png'\n",
        "image_path2 = file_path + \"Testing/\"+\"Method_3_\"+str(size)+\"LAB_\"+filename\n",
        "\n",
        "# Load images\n",
        "image1 = load_image(image_path1)\n",
        "image2 = load_image(image_path2)\n",
        "\n",
        "# Ensure the images have the same dimensions\n",
        "if image1.shape != image2.shape:\n",
        "    raise ValueError(\"Input images must have the same dimensions.\")\n",
        "\n",
        "# Compute SSIM for each channel and average the results\n",
        "ssim_index_r = ssim(image1[:, :, 0], image2[:, :, 0], data_range=image1[:, :, 0].max() - image1[:, :, 0].min())\n",
        "ssim_index_g = ssim(image1[:, :, 1], image2[:, :, 1], data_range=image1[:, :, 1].max() - image1[:, :, 1].min())\n",
        "ssim_index_b = ssim(image1[:, :, 2], image2[:, :, 2], data_range=image1[:, :, 2].max() - image1[:, :, 2].min())\n",
        "\n",
        "ssim_index_rgb = (ssim_index_r + ssim_index_g + ssim_index_b) / 3\n",
        "\n",
        "print(f\"SSIM for R channel: {ssim_index_r}\")\n",
        "print(f\"SSIM for G channel: {ssim_index_g}\")\n",
        "print(f\"SSIM for B channel: {ssim_index_b}\")\n",
        "print(f\"Average SSIM for RGB image(Method3): {ssim_index_rgb}\")\n"
      ],
      "metadata": {
        "id": "MHIfhhpLHwNf",
        "outputId": "627c1f49-a23a-4e21-e02f-23c909e3a196",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SSIM for R channel: 0.509358346147561\n",
            "SSIM for G channel: 0.5081811788128479\n",
            "SSIM for B channel: 0.4024215496836909\n",
            "Average SSIM for RGB image(Method3): 0.4733203582146999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Function to open image and convert to numpy array\n",
        "def load_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')  # Ensure image is in RGB mode\n",
        "    return np.array(image)\n",
        "\n",
        "image_path1 = file_path + 'Testing/OUTPUT_[05] Comprimise-d.png'\n",
        "image_path2 = file_path + \"Testing/\"+\"Method_4_\"+str(size)+\"L_AB_\"+filename\n",
        "\n",
        "# Load images\n",
        "image1 = load_image(image_path1)\n",
        "image2 = load_image(image_path2)\n",
        "\n",
        "# Ensure the images have the same dimensions\n",
        "if image1.shape != image2.shape:\n",
        "    raise ValueError(\"Input images must have the same dimensions.\")\n",
        "\n",
        "# Compute SSIM for each channel and average the results\n",
        "ssim_index_r = ssim(image1[:, :, 0], image2[:, :, 0], data_range=image1[:, :, 0].max() - image1[:, :, 0].min())\n",
        "ssim_index_g = ssim(image1[:, :, 1], image2[:, :, 1], data_range=image1[:, :, 1].max() - image1[:, :, 1].min())\n",
        "ssim_index_b = ssim(image1[:, :, 2], image2[:, :, 2], data_range=image1[:, :, 2].max() - image1[:, :, 2].min())\n",
        "\n",
        "ssim_index_rgb = (ssim_index_r + ssim_index_g + ssim_index_b) / 3\n",
        "\n",
        "print(f\"SSIM for R channel: {ssim_index_r}\")\n",
        "print(f\"SSIM for G channel: {ssim_index_g}\")\n",
        "print(f\"SSIM for B channel: {ssim_index_b}\")\n",
        "print(f\"Average SSIM for RGB image(Method4): {ssim_index_rgb}\")\n"
      ],
      "metadata": {
        "id": "K_XXHvyDNokf",
        "outputId": "cd917983-a029-457c-ba09-72d2993273bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SSIM for R channel: 0.5487580309946481\n",
            "SSIM for G channel: 0.5692294383749303\n",
            "SSIM for B channel: 0.4253035732161732\n",
            "Average SSIM for RGB image(Method4): 0.514430347528584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "def compute_average_ssim(image1_path, image2_path):\n",
        "    # Open the images using Pillow\n",
        "    image1 = Image.open(image1_path).convert('RGB')\n",
        "    image2 = Image.open(image2_path).convert('RGB')\n",
        "\n",
        "    # Convert images from RGB to LAB color space using Pillow\n",
        "    lab_image1 = image1.convert('LAB')\n",
        "    lab_image2 = image2.convert('LAB')\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    lab_image1 = np.array(lab_image1)\n",
        "    lab_image2 = np.array(lab_image2)\n",
        "\n",
        "    # Extract the A and B channels\n",
        "    a_channel1, b_channel1 = lab_image1[:, :, 1], lab_image1[:, :, 2]\n",
        "    a_channel2, b_channel2 = lab_image2[:, :, 1], lab_image2[:, :, 2]\n",
        "\n",
        "    # Compute SSIM for the A channel\n",
        "    ssim_a = ssim(a_channel1, a_channel2)\n",
        "\n",
        "    # Compute SSIM for the B channel\n",
        "    ssim_b = ssim(b_channel1, b_channel2)\n",
        "\n",
        "    # Average the SSIM values\n",
        "    average_ssim = (ssim_a + ssim_b) / 2\n",
        "\n",
        "    return average_ssim\n",
        "\n",
        "# Paths to the images\n",
        "image1_path = file_path + 'Testing/OUTPUT_[05] Comprimise-d.png'\n",
        "image2_path = image_path2 = file_path + \"Testing/\"+\"Method_3_\"+str(size)+\"LAB_\"+filename\n",
        "\n",
        "# Compute the average SSIM\n",
        "average_ssim_value = compute_average_ssim(image1_path, image2_path)\n",
        "print(f\"Average SSIM (A and B channels (Method3)): {average_ssim_value}\")\n"
      ],
      "metadata": {
        "id": "FK867a9sNxwM",
        "outputId": "be49afbb-ce9c-40c9-c7e1-7a32b21e2081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average SSIM (A and B channels (Method3)): 0.4829091381886401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "def compute_average_ssim(image1_path, image2_path):\n",
        "    # Open the images using Pillow\n",
        "    image1 = Image.open(image1_path).convert('RGB')\n",
        "    image2 = Image.open(image2_path).convert('RGB')\n",
        "\n",
        "    # Convert images from RGB to LAB color space using Pillow\n",
        "    lab_image1 = image1.convert('LAB')\n",
        "    lab_image2 = image2.convert('LAB')\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    lab_image1 = np.array(lab_image1)\n",
        "    lab_image2 = np.array(lab_image2)\n",
        "\n",
        "    # Extract the A and B channels\n",
        "    a_channel1, b_channel1 = lab_image1[:, :, 1], lab_image1[:, :, 2]\n",
        "    a_channel2, b_channel2 = lab_image2[:, :, 1], lab_image2[:, :, 2]\n",
        "\n",
        "    # Compute SSIM for the A channel\n",
        "    ssim_a = ssim(a_channel1, a_channel2)\n",
        "\n",
        "    # Compute SSIM for the B channel\n",
        "    ssim_b = ssim(b_channel1, b_channel2)\n",
        "\n",
        "    # Average the SSIM values\n",
        "    average_ssim = (ssim_a + ssim_b) / 2\n",
        "\n",
        "    return average_ssim\n",
        "\n",
        "# Paths to the images\n",
        "image1_path = file_path + 'Testing/OUTPUT_[05] Comprimise-d.png'\n",
        "image2_path = image_path2 = file_path + \"Testing/\"+\"Method_4_\"+str(size)+\"L_AB_\"+filename\n",
        "\n",
        "# Compute the average SSIM\n",
        "average_ssim_value = compute_average_ssim(image1_path, image2_path)\n",
        "print(f\"Average SSIM (A and B channels (Method4)): {average_ssim_value}\")\n"
      ],
      "metadata": {
        "id": "HJJHBbh3SHZO",
        "outputId": "968b80df-3f0f-4714-83ad-270f209f7aad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average SSIM (A and B channels (Method4)): 0.4836187382989704\n"
          ]
        }
      ]
    }
  ]
}